{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------- ----------------------------------- ----------------------------------- \n",
    "----------------------------------- ESPACIO PARA BANNER DE LA MAESTRIA -----------------------------------\n",
    "----------------------------------- ----------------------------------- ----------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descomposici√≥n en Valores Singulares. Detalles Algebr√°icos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este *cuaderno* cubre detalles sobre el algebra de la descomposici√≥n en valores singulares. El objetivo del *cuaderno* es que aprenda el funcionamiento de la descomposici√≥n en valores singulares, y a construir e implementar este m√©todo. Al final encontrar√° ejercicios asociados a los contenidos del cuaderno para que los resuelva por su propia cuenta (no debe entregarlos).  Si tiene dudas sobre los contenidos o los ejercicios, consulte con el tutor.\n",
    "\n",
    "\n",
    "**NO** es necesario editar el archivo o hacer una entrega. Los ejemplos contienen celdas con c√≥digo ejecutable (`en gris`), que podr√° modificar  libremente. Esta puede ser una buena forma de aprender nuevas funcionalidades del *cuaderno*, o experimentar variaciones en los c√≥digos de ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/the-andela-way/foundations-of-machine-learning-singular-value-decomposition-svd-162ac796c27d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducci√≥n\n",
    "\n",
    "En el cuaderno *Fundamentos Te√≥ricos* mostramos que la SVD es la factorizacion de una matriz en 3 matrices. Entonces si tenemos una matrix real $X$ de dimensi√≥n $n\\times k$, entonces su SVD esta representada por:\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{n\\times k}{\\underbrace{X}}=\\underset{n\\times n}{\\underbrace{U}}\\underset{n\\times k}{\\underbrace{S}}\\underset{k\\times k}{\\underbrace{V'}}\n",
    "\\end{align}\n",
    "\n",
    "donde $U$ es una matriz $n\\times n$ cuyas columnas son ortogonales $(U'U=I_{n})$, $V$ es una matriz $k\\times k$ cuyas filas y columnas son tambi√©n ortogonales $(V'V=VV'=I_{k})$, y $S$ es una matriz $n\\times k$ que contiene los $r=min(n,k)$ valores singulares $(\\sigma_{i}\\geq0)$ en la diagonal principal, y 0 en el resto de la matriz. \n",
    "\n",
    "A $U$ se la suele denominar como la matriz de vectores singulares izquierdos, S como los valores singulares, y $V$ como los valores singulares derechos.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar como funciona la descomposici√≥n geometricamente, supongamos que tenemos un c√≠rculo en 2 dimensiones representado por 2 vectores $v_1$ y $v_2$ como lo muestra la siguiente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:500px\">\n",
    "<img src = \"figs/rot1.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La SVD implica aplicar una transformaci√≥n matricial a estos dos vectores de forma tal que vamos a obtener dos nuevos vectores $\\sigma_1 u_1$ y $\\sigma_2 u_2$:\n",
    "\n",
    "\\begin{align}\n",
    "XV=US \n",
    "\\end{align}\n",
    "donde V es la matriz cuyas columnas son los vectores $v_1$ y $v_2$, $X$ es la matriz de datos, S la matriz diagonal de $\\sigma_1$ y $\\sigma_2$ y U la matriz de los vectores $u_1$ y $u_2$. Esta transformaci√≥n equivale a \"estirar\" el c√≠rculo como lo muestra la siguiente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:500px\">\n",
    "<img src = \"figs/rot2.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso los valores singulars $\\sigma$ son los factores que estiran. Notemos adem√°s que las columnas de $V$ son ortogonales, por lo que podemos hacer:\n",
    "\n",
    "\\begin{align}\n",
    "XV&=US \\\\\n",
    "XVV'&=USV' \\\\\n",
    "X &=USV'\n",
    "\\end{align}\n",
    "\n",
    "donde obtenemos la expresion original. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So this is how you can decompose a matrix into three lower rank matrices.\n",
    "\n",
    "Let‚Äôs look at a classical application of this. Imagine that we have a matrix A whose columns represent movies and the rows different users. The entries of the matrix are numbers 0 to 5 where 0 means a user does not like a certain movie and 5 means they really like a given movie as illustrated below:\n",
    "\n",
    "Now imagine that the first 3 columns are the movies Avengers, StarWars and IronMan respectively(Sci-Fi movies). While the last 2 columns are the movies Titanic and Notebook (Romance movies).\n",
    "\n",
    "After performing SVD on matrix A we get the matrices Uùö∫V as illustrated below(using a tool like or sklearn):\n",
    "\n",
    "Let‚Äôs take a closer look at these three matrices starting with U:\n",
    "\n",
    "So the first column of U represents weights that would match each user‚Äôs preference to movies categorized under Sci-Fi while the second column of U represents weights that would match each user‚Äôs preference to movies under the romance category. For example, the first user greatly prefers sci-fi movies(0.13 score) compared to romance(0.02 score). As for the third column, we won‚Äôt consider it for now.\n",
    "\n",
    "And for ùö∫,\n",
    "\n",
    "The first diagonal entry represents the weight of the Sci-Fi category and the second diagonal entry represents the weight of the romance category.\n",
    "\n",
    "And for V,\n",
    "\n",
    "The columns depict the degree to which a movie belongs to a category. So, for example, we can see from the first column of V that the first movie(this would be Avengers) belongs heavily to the Sci-Fi(0.56 score) category and very little to the romance category(0.12 score).\n",
    "\n",
    "    Note: we have not considered the third dimension of each matrix at all. Well, this is because when you look at matrix ùö∫, the third diagonal entry which represents the weight of a movie category has a small value(1.3 score). This is understandable because we only have two categories of movies. So most of the third dimension is considered as noise.\n",
    "\n",
    "So its the above note that we use to perform dimensionality reduction to the matrices A. We do this by eliminating the third dimension of ùö∫, this would also mean eliminating the third column of U and the third row of V to produce the following new U, ùö∫ and, V:\n",
    "\n",
    "So as you can see, the final matrices Uùö∫V are smaller than the initial ones since we have eliminated the third dimension.\n",
    "\n",
    "To confirm that eliminating the given rows and columns as we have done only affects the initial matrix A to a small extent. Let‚Äôs multiply the above three matrices to get matrix B below:\n",
    "\n",
    "So Let‚Äôs compare this matrix B with the original matrix A below:\n",
    "\n",
    "Just by looking at the above two matrices, you can tell that the difference between their elements is very small, in other words, the product of our final three matrices B(after SVD) ‚âà A(before SVD):\n",
    "\n",
    "Or mathematically this can be represented as the Frobenius norm. Which is the square root of the summation of the squares of the differences between the individual matrix entries. It can be represented by the equation below:\n",
    "\n",
    "So this is how we are able to decompose a matrix into lower rank matrices without losing much of the important data.\n",
    "\n",
    "It also helps to analyse and acquire important information concerning the matrix data.\n",
    "\n",
    "There are many other applications of SVD other than the ones talked about in this article. Some of the others include data compression, solving the pseudo-inverse and search engines like Google use SVD to compute approximations of enormous matrices that provide compression ratios of millions to one. So searching for a term is much quicker.\n",
    "\n",
    "So hopefully this reading can give you a clear picture of this fundamental linear algebra concept and its application in Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios te√≥ricos\n",
    "\n",
    "\n",
    "Resuelva los siguientes problemas. Intente realizarlos primero sin ayuda de `Python` y luego verifique su soluci√≥n con los comandos de `Python`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Demuestre que la Descomposici√≥n en Valores Singulares encuentra la direcci√≥n para la cual la matriz original estira m√°s el vector unitario. Parta de la siguiente expresi√≥n:\n",
    "$$\\argmax_{x:||x||=1} ||Bx||$$\n",
    "2. $B$ es una matriz cuadrada de tama√±o $m\\times m$ la cual sus filas son ortonormales. Demuestre que las columnas de $B$ tambi√©n son ortonormales.\n",
    "3. Suponga que $C$ es una matriz cuadrada invertible y que la Descomposici√≥n en Valores Singulares de $C$ es $C=\\sum_i \\sigma_i u_i v_i^T$. Encuentre la inversa de $C$.\n",
    "4. Encuentre la DVS o SVD de la matriz $A$, $U\\Sigma V^T$, en donde $A = \\begin{bmatrix} 3 & 2 & 2 \\\\ 2 & 3 & -2 \\end{bmatrix}$\n",
    "5. Demuestre que los vectores singulares izquierdos de una matriz $D$ son los vectores singulares derechos de $D^T$\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
