{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado de Tópicos \n",
    "\n",
    "Este *cuaderno* trata sobre modelado de tópicos a partir de datos de texto. El objetivo del *cuaderno* es que usted obtenga una visión general del modelo de asignación latente de Dirichlet (LDA, por sus siglas en inglés). Busca tambien que sea capaz de crear e implementar este modelo en `Python` y que sea  capaz evaluar de interpretar los resultados e identificar el mejor modelo de tópicos para un determinado problema. \n",
    "\n",
    "**NO** es necesario editar el archivo o hacer una entrega. Sin embargo, los ejemplos contienen celdas con código ejecutable (`en gris`), que podrá modificar  libremente. Esta puede ser una buena forma de aprender nuevas funcionalidades del *cuaderno*, o experimentar variaciones en los códigos de ejemplo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "El modelado de tópicos o temas es una faceta del procesamiento del lenguaje natural (NLP, por sus siglas en inglés). Como vimos anteriormente utilizar el lenguaje, textos, como datos puede ser extremadamente poderoso. En este *cuaderno* nos centraremos sobre el modelado de tópicos. Inmediatamente nos surge la pregunta ¿qué son los tópicos? Responderemos esa pregunta con un ejemplo. Habremos notado que en los días en que se llevan a cabo eventos importantes (como elecciones nacionales, desastres naturales o eventos deportivos), las publicaciones de las redes sociales tienden a centrarse en esos eventos. Las publicaciones de alguna manera reflejan los eventos del día, y lo hacen de diferentes maneras. Las publicaciones pueden tener, y tendrán, puntos de vista divergentes que pueden ser agrupados en clústeres de tópicos de alto nivel. Si tuviéramos tweets sobre la final del Mundial, los tópicos de esos tweets podrían cubrir puntos de vista divergentes, que van desde la calidad del arbitraje al comportamiento de los aficionados. En Estados Unidos, el presidente realiza un discurso anual entre mediados y finales de enero llamado Estado de la Unión. Con un número suficiente de publicaciones en las redes sociales, podríamos inferir o predecir las reacciones de alto nivel (tópicos) al discurso. Esto lo lograríamos agrupando las publicaciones usando las palabras claves contenidas en ellos. Por ejemplo la siguiente figura con un breve texto sobre ciencia de datos muestra como se pueden identificar palabras y asignarlas a tópicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/topicos1.jpg\" alt = \"topicos\" style = \"width: 500px;\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En  la figura entonces se muestra como palabras como información, predicció, estadística son asignadas al tópico de modelado; mientras que computacional, produccion y escala son asignadas al tópico de ingeniería. Los modelos de tópicos son importantes porque ofrecen la misma función para los datos textuales que las estadísticas clásicas para los datos numéricos. Es decir que proporcionan un resumen significativo de los datos. \n",
    "\n",
    "Los modelos de tópicos entran en la categoría de aprendizaje no supervisado porque, casi siempre, no se conocen de antemano los tópicos subyacentes de los documentos. Por lo tanto, no existe una variable que guie el aprendizaje. En términos de aprendizaje no supervisado, los modelos de tópicos se pueden pensar como parte del análisis de clusters, más específicamente a K-medias. Recordemos que con K-medias, primero se establece el número de clusters y luego el modelo asigna cada uno de los datos a uno de los clústers predeterminados. Lo mismo ocurre generalmente con los modelos de tópicos. Seleccionamos el número de tópicos al inicio y luego el modelo aísla las palabras que forman esa cantidad de tópicos. Este es un excelente punto de partida para una descripción general de modelado de tópicos de alto nivel.\n",
    "\n",
    "\n",
    "Los modelos de tópicos buscan encontrar patrones comunes en el texto en el sentido de que los documentos descrien tópicos similares. Es decir, estos modelos identifican los tópicos abstractos en una colección de documentos (también referidos como corpus), utilizando las palabras contenidas en los documentos.  Para ello asumen que las palabras en el mismo documento están relacionadas y usan esa suposición para definir tópicos abstractos al encontrar grupos de palabras que aparecen con frecuencia una cerca de otra.  Es decir, si una oración contiene las palabras salario, empleado, y reunión, podemos asumir que esa oración trata o que su tópico es el trabajo. .  \n",
    "\n",
    "Este tipo de algoritmos por lo general consta de cuatro pasos:\n",
    "\n",
    "1. Determinar el número de tópicos.\n",
    "2. Identificar palabras o frases concurrentes en los documentos.\n",
    "3. Buscar clusters de palabras que caracterizan el documentos.\n",
    "4. Retornar un conjunto de tópicos abstractos que caracterizan el corpus.\n",
    "\n",
    "Un aspecto clave de los modelos de tópicos es que no producen tópicos específicos de una palabra o una frase, sino conjunto de palabras, cada una de las cuales representa un tópico abstracto. Esto se debe a que los modelos de tópicos entienden la proximidad de las palabras, no el contexto. Por ejemplo en la figura siguiente, el modelo no tiene idea de lo que significan ala, elevar, piloto, equipaje, pasajer, o mosca; sólo sabe que estas palabras, generalmente, siempre que aparecen, aparecen muy próximas entre sí. Será nuestra tarea darle una interpretación (o no) a este tópico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src = \"figs/topicos3.jpg\" alt = \"topicos3\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varios algoritmos de modelado de tópicos, pero quizás el más conocidos es el de Asignación latente de Dirichlet, o Latent Dirichlet Allocation (LDA) en inglés. En este *cuaderno* nos centraremos en este."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación latente de Dirichlet (LDA)\n",
    "\n",
    "En 2003, David Blei, Andrew Ng, y Michael Jordan publicaron un artículo sobre el algoritmo del modelado de tópicos conocido como Latent Dirichlet Allocation (LDA). LDA es un modelo probabilístico generativo, esto significa que el proceso de modelado comienza con el texto y funciona como ingeniería reversa a través del proceso que suponemos que lo generó, con el fin de identificar los parámetros de interés. En este caso, son los tópicos que generaron los datos que son de interés. \n",
    "\n",
    "Esencialmente LDA es una técnica de clustering que puede ser aplicada a colecciones de datos discretos como los son los documentos de texto. LDA es un modelo bayesiano jerárquico de tres niveles en donde cada elemento o palabra de un texto se modela como una mezcla finita de tópicos. A su vez, cada tópico se modela como una combinación infinita de palabras. En este contexto, decimos que LDA es un modelo probabilístico generativo pues estas distribuciones resultan en una representación explícita de cada conjunto de datos o documento.\n",
    "\n",
    "Esta técnica de aprendizaje no supervisado se diferencia de las técnicas de clustering estudiadas anteriormente porque en este caso cada observación pertenece a más de un grupo. En ese orden de ideas, se puede decir que LDA es una técnica de agrupamiento difuso (*fuzzy o soft clustering*) donde la pertenencia de un elemento a un grupo se modela como una distribución de probabilidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up del modelo\n",
    "\n",
    "La intución detras del modelo es que los documentos pueden ser representados como una combinación aleatoria de los tópicos latentes, donde cada tópico está caracterizado por una distribución de probabilidad sobre las palabras.\n",
    "\n",
    "Para poder describir como funciona el modelo necesitamos primero definir ciertos términos:\n",
    "\n",
    "- Una *palabra* es la unidad básica de los datos discretos. Definimos una palabra como un item de un vocabulario indexado por $\\{1, \\cdots, V\\}$. Se representan las palabras mediante vectores de base uno, es decir, un vector donde solo un elemento es 1 y el resto son 0. Así, usando superíndices para denotar componentes, la v-ésima palabra en el vocabulario se representa mediante un V-vector $w$ tal que $w^v = 1$ y $w^u = 0$ para $u\\neq v$.\n",
    "- Un *documento* es una secuencia de $N$ palabras denotadas por $\\mathbf{w}=(w_1,w_2,\\cdots,w_N)$, en donde $w_n$ es la n-ésima palabra de la secuencia. \n",
    "- Un *corpus* es una colección de $M$ documentos dentodas por $\\mathbf{D}=(\\mathbf{w_1},\\mathbf{w_2},\\cdots,\\mathbf{w_m})$.\n",
    "\n",
    "\n",
    "Para cada documento del corpus, LDA supone los siguientes procesos generadores de cada documento $\\mathbf(w)$ en el corpus $D$:\n",
    "\n",
    "1. Elegimos $N\\sim Poisson(\\xi)$., donde $N$ es el número de palabras y $\\xi$ es el parámetro que controla  distribución de Poisson.\n",
    "2. Elegimos $\\theta\\sim Dir(\\alpha)$, donde $\\theta$ es la distribución de tópicos.\n",
    "3. Para cada palabra $w_n$ de las $N$ palabras:\n",
    "\n",
    "    a. Escogemos un tópico $z_n\\sim Multinomial(\\theta)$.\n",
    "    \n",
    "    b. Escogemos una palabra $w_n$ de $p(w_n|z_n, \\beta)$, una probabilidad condicionada en el tópico $z_n$.\n",
    "\n",
    "\n",
    "Estos tres paso se repiten para cada documento en el corpus. El primer paso es elegir el número de palabras en el documento tomando muestras, de la distribución de Poisson.\n",
    "\n",
    "Luego de seleccionar $N$, debemos generar la distribución de tópicos, únicos para cada documento. Pensemos en esto como una lista de tópicos por documento con probabilidades de que representan el monto del documento representado por cada tópico. Consideremos tres tópicos: A, B y C. Un ejemplo podría ser 100% del tópico A, 75% del tópico B y 25% del tópico C, o una infinidad de otras combinaciones.\n",
    "\n",
    "Por último, las palabras específicas en el documento se seleccionarán a través de una declaración de probabilidad condicionado al tópico seleccionado y la distribución de palabras para ese tópico. Tener en cuenta  que los documentos no se generan realmente de esta manera, pero es un proxy razonable.\n",
    "\n",
    "Este proceso puede considerarse como una distribución sobre distribuciones. Un documento es\n",
    "seleccionado de la colección (distribución) de documentos, y se selecciona un tópico (a través de la distribución multinomial) de la distribución de probabilidad de tópicos para ese documento, generado por la distribución de Dirichlet.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Este modelo inicial cuenta con algunas simplificaciones que más adelante serán removidas. En primer lugar, la dimensionalidad $k$ de la distribución Dirichlet (y por consiguiente la dimensionalidad de la variables de los tópicos $z$) se supone fija y conocida. Segundo, las probabilidades de cada palabra son parametrizadas por una matriz $\\beta$ de tamaño $k\\times V$ en donde $\\beta_{ij}=p(w^j = 1|z^i = 1)$, que por ahora trataremos como una cantidad fija que será estimada. Finalmente, el supuesto de $N$ distribuido Poisson no es critico ya que otras distribuciones más realistas sobre la longitud de los documentos pueden ser usadas según la necesidad del investigador. Más aún, note que $N$ es independiente del resto de variables generadoras ($\\theta$ y $\\mathbf{z}$) por tanto ignoraremos su aleatoriedad en el desarrollo posterior.\n",
    "\n",
    "Una variable aleatoria $\\theta$ de dimensión $k$ puede tomar valores en el $(k-1)-símplex$ (un vector de dimensión $k$ llamado $\\theta$ cae en el $(k-1)-símplex$ si $\\theta_i\\geq0, \\sum_{i=1}^k\\theta_i=1$), y tiene la siguiente función de densidad en el símplex:\n",
    "\n",
    "$$p(\\theta|\\alpha)=\\frac{\\Gamma(\\sum_{i=1}^k\\alpha_i)}{\\prod_{i=1}^k\\Gamma(\\alpha_i)}\\theta_1^{(\\alpha_1-1)}\\cdots \\theta_k^{(\\alpha_k-1)}$$\n",
    "\n",
    "En donde el parámetro $\\alpha$ es un vector de dimensión $k$ con componentes $a_i$ tal que $a_i\\geq0$, y $\\Gamma(x)$ es la función Gamma. La Dirichlet es una distribución conveniente para el símplex porque está en la familia exponencial, tiene estadísticas suficientes de dimensión finita y es conjugada a la distribución multinomial.\n",
    "\n",
    "Antes de continuar, vale la pena profundizar un poco sobre qué es un símplex y por qué es relevante en este modelo. Podemos pensar en el LDA como una aproximación geométrica en donde el símplex es una figura con $k$ vertices equidistantes entre ellos. Un 0-símplex es un punto, un 1-símplex es un segmento de línea, un 2-símplex es un triángulo, un 3-símplex es un tetraedro y un 4-símplex es un pentácoron.\n",
    "\n",
    "<center>\n",
    "<img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Simplexes.jpg/800px-Simplexes.jpg\" alt = \"simplex\" style = \"width: 500px;\"/>\n",
    "</center>\n",
    "\n",
    "En el caso de LDA, los documentos dentro del corpus se distribuirían a lo largo del símplex en donde cada vértice se representa un tópico. Luego, cada documento se ubicaría más cercano a los vértices que representan los tópicos contenidos en él. Por ejemplo, supongamos que tenemos 7 documentos y tres tópicos posibles (Deporte, Ciencia y Política), podríamos representar los documentos dentro del símplex de la siguiente manera:\n",
    "\n",
    "<center>\n",
    "<img src = \"data/2-simplex.png\" alt = \"LDA\" style = \"width: 500px;\"/>\n",
    "</center>\n",
    "\n",
    "De esta manera podríamos ver que cada documento es una combinación de tópicos. El documento 1 sería 100% sobre Deportes, el documento 2 sería 50% sobre Deportes y 50% sobre Ciencia, el documento 3 sería 100% sobre Ciencia, etc.\n",
    "\n",
    "Continuando con nuestra explicación del modelo. Tomando como dados los parámetros $\\alpha$ y $\\beta$, la distribución de probabilidad conjunta de una mezcla de tópicos $\\theta$, un conjunto de $N$ temas $\\mathbf{z}$ y un conjunto de $N$ palabras $\\mathbf{w}$ es:\n",
    "\n",
    "$$p(\\theta, \\mathbf{z}, \\mathbf{w}|\\alpha, \\beta) = p(\\theta|\\alpha)\\prod_{n=1}^N p(z_n|\\theta)p(w_n|z_n, \\beta)$$\n",
    "\n",
    "En donde $p(z_n|\\theta)$ es simplemente $\\theta_i$ para el único $i$ en donde $z_n^i=1$. \n",
    "\n",
    "A continuación se muestra una representación gráfica del modelo. El rectángulo exterior M representa los documentos y el rectángulo interior N representa la escogencia repetida de palabras ($w$) y tópicos ($z$) al interior de un documento.\n",
    "\n",
    "<center>\n",
    "<img src = \"data/LDA1.png\" alt = \"LDA1\" style = \"width: 500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la expresión anterior podemos decir que el lado izquierdo de la ecuación ($p(\\theta, \\mathbf{z}, \\mathbf{w}|\\alpha, \\beta)$) corresponde a la probabilidad de que un documento $x$ aparezca en nuestro corpus. De este modo, nuestro objetivo será estimar $\\alpha$ y $\\beta$ de modo que se maximice la probabilidad de encontrar nuestra muestra de documentos.\n",
    "\n",
    "La Figura anterior corresponde a una ilustración de la ecuación en cuestión. En donde $\\alpha$ es una distribución Dirichlet que le asigna una combinación de tópicos a cada uno de los documentos. $\\beta$ es una distribución Dirichlet que le asigna una combinación de palabras a cada uno de los tópicos. A partir de $\\alpha$ obtenemos $\\theta$ la cual es una distribución multinomial de donde se extraen $N$ tópicos. Luego, para cada uno de los tópicos se extrae una palabra de la distribución multinomial que sale de $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencia variacional\n",
    "El principal problema de inferencia al que nos enfrentamos a la hora de usar LDA es el cálculo de la distribución posterior de las variables escondidas dado un documento:\n",
    "\n",
    "$$p(\\theta, \\mathbf{z}|\\mathbf{w},\\alpha, \\beta)=\\frac{p(\\theta, \\mathbf{z}, \\mathbf{w}|\\alpha, \\beta)}{p(\\mathbf{w}|\\alpha, \\beta)}$$\n",
    "\n",
    "Desafortunadamente, esta distribución no se puede calcular directamente, por ende se debe aproximar numéricamente. Entre los métodos que existen para aproximarnos a la solución están la aproximación de Laplace, Aproximación variacional, Cadena de Makov Monte Carlo, etc.\n",
    "\n",
    "En esta sección vamos a describir la intuición detrás de un algoritmo variacional simple basado en la convexidad. La idea principal detrás de este método es hacer uso de la [Desigualdad de Jensen](https://es.wikipedia.org/wiki/Desigualdad_de_Jensen) para obtener un límite inferior ajustable en la log-verosimilitud. En esencia, se considera una familia de límites inferiores indexada a un conjunto de *parámetros variacionales*. Los parámetros variacionales se eligen mediante un procedimiento de optimización que intenta encontrar el límite inferior más ajustado posible.\n",
    "\n",
    "De forma más intuitiva podemos explicar el algoritmo de la siguiente manera:\n",
    "1. Comience asignando aleatoriamente cada palabra de cada documento del corpus a uno de los temas.\n",
    "2. Para cada documento y cada palabra en cada documento por separado, calcule dos proporciones:\n",
    "    - La proporción de palabras en el documento que están actualmente asignadas al tema: $p(Tema|Documento)$\n",
    "    - La proporción de asignaciones en todos los documentos de una palabra específica al tema: $p(Palabra|Tema)$\n",
    "3. Multiplique las dos proporciones y use la proporción resultante para asignar la palabra a un nuevo tema. \n",
    "4. Repita este proceso hasta que se alcance un estado estable en el que las asignaciones de temas no cambien significativamente. Estas asignaciones luego se utilizan para estimar la mezcla de temas dentro del documento y la mezcla de palabras dentro del tema.\n",
    "\n",
    "La lógica detrás de la inferencia variacional es que, si la distribución real es intratable, entonces se debe encontrar una distribución más simple, llamémosla distribución variacional, muy cercana a la distribución verdadera, que es manejable, para que la inferencia sea posible. En otras palabras, dado que es imposible inferir la distribución real debido a la complejidad de la distribución real, tratamos de encontrar una distribución más simple que sea una excelente aproximación de la distribución real.\n",
    "\n",
    "En nuestro caso, el problema de inferencia se da por el acomplamiento entre los parámetros $\\beta$ y $\\theta$ debido a los enlaces entre $\\theta$, $\\mathbf{z}$ y $\\mathbf{w}$. Eliminando estas aristas y los nodos $\\mathbf{w}$, y dotando al modelo gráfico simplificado resultante de parámetros variacionales libres, obtenemos una familia de distribuciones de las variables latentes. Esta familia se caracteriza por la siguiente distribución variacional:\n",
    "\n",
    "$$q(\\theta, \\mathbf{z} | \\gamma, \\phi) = q(\\theta|\\gamma)\\prod_{n=1}^N q(z_n|\\phi_n)$$\n",
    "\n",
    "En donde $\\gamma$ es el parámetro Dirichlet y los parámetros multinomiales $(\\phi_1,\\cdots, \\phi_N)$ son los parámetros variacionales libres. A continuación se ilustra gráficamente la representación del modelo de la distribución variacional utilizada para aproximar la distribución posterior en LDA.\n",
    "\n",
    "<center>\n",
    "<img src = \"data/LDA2.png\" alt = \"LDA2\" style = \"width: 300px;\"/>\n",
    "</center>\n",
    "\n",
    "Para comenzar, se selecciona una familia de distribuciones (es decir, binomial, gaussiana, exponencial, etc.), $q$, condicionada a los nuevos parámetros variacionales. Los parámetros están optimizados para que la distribución original (que en realidad es la distribución posterior), y la distribución variacional sean lo más parecidas posible. La distribución variacional será lo suficientemente cercana a la distribución posterior original para ser utilizada como proxy, haciendo que cualquier inferencia hecha sobre ella sea aplicable a la distribución posterior original.\n",
    "\n",
    "El objetivo de encontrar un límite inferior ajustado en la log-verosimilitud se traduce directamente en el siguiente problema de optimización para determinar los parámetros variacionales $\\gamma$ y $\\phi$:\n",
    "\n",
    "$$(\\gamma^*,\\phi^*)=\\argmin_{(\\gamma,\\phi)} D(q(\\theta, \\mathbf{z}|\\gamma,\\phi)\\ ||\\ p(\\theta, \\mathbf{z}|\\mathbf{w}, \\alpha, \\beta))$$\n",
    "\n",
    "Hay una gran colección de distribuciones variacionales potenciales que se pueden usar como una aproximación para la distribución posterior. Se selecciona una distribución variacional inicial de la colección, que actúa como punto de partida para un proceso de optimización que iterativamente se acerca más y más a la distribución óptima. Los parámetros óptimos son los parámetros de la distribución que mejor se aproximan al posterior. La similitud de las dos distribuciones se mide utilizando la divergencia de [Kullback-Leibler (KL)](https://es.wikipedia.org/wiki/Divergencia_de_Kullback-Leibler). La divergencia KL representa la cantidad esperada de error generado si aproximamos una distribución con otra. La distribución con parámetros óptimos tendrá la divergencia KL más pequeña cuando se mida con la distribución real. \n",
    "\n",
    "Una vez que se ha identificado la distribución óptima, lo que significa que se han identificado los parámetros óptimos, se puede aprovechar para producir las matrices de salida y ejecutar cualquier inferencia requerida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicación de LDA\n",
    "En este Notebook usaremos datos de comentarios realizados por usuarios de Tripadvisor a restaurantes en Bogotá. El objetivo es aplicar la técnica de LDA para extraer algunos tópicos del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos importando la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enlaces_tripadvisor.csv',\n",
       " 'comentarios_tripadvisor.csv',\n",
       " '2-simplex.png',\n",
       " 'LDA1.png',\n",
       " 'LDA2.png',\n",
       " '.ipynb_checkpoints',\n",
       " 'Scraping_tripadvisor.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>link</th>\n",
       "      <th>puntaje_global</th>\n",
       "      <th>n_comentarios</th>\n",
       "      <th>posicion_relativa</th>\n",
       "      <th>n_restaurantes</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>excelente</th>\n",
       "      <th>muy_bueno</th>\n",
       "      <th>...</th>\n",
       "      <th>características</th>\n",
       "      <th>usuario</th>\n",
       "      <th>relevancia_usuario</th>\n",
       "      <th>fecha_comentario</th>\n",
       "      <th>titulo_comentario</th>\n",
       "      <th>contenido_comentario</th>\n",
       "      <th>fecha_visita</th>\n",
       "      <th>puntaje</th>\n",
       "      <th>rango_de_precios</th>\n",
       "      <th>dietas_especiales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asadero Cimarron del Llano</td>\n",
       "      <td>/Restaurant_Review-g294074-d10003846-Reviews-A...</td>\n",
       "      <td>4,0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>4.666695</td>\n",
       "      <td>-74.113075</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Comida para llevar, Servicio de mesa, Reservas...</td>\n",
       "      <td>Marylyn73</td>\n",
       "      <td>4 opiniones</td>\n",
       "      <td>Escribió una opinión el 6 de enero de 2021</td>\n",
       "      <td>Comida recalentada</td>\n",
       "      <td>Fui temprano para evitar aglomeraciones y me t...</td>\n",
       "      <td>enero de 2021</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asadero Cimarron del Llano</td>\n",
       "      <td>/Restaurant_Review-g294074-d10003846-Reviews-A...</td>\n",
       "      <td>4,0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>4.666695</td>\n",
       "      <td>-74.113075</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Comida para llevar, Servicio de mesa, Reservas...</td>\n",
       "      <td>jairoenriquer2020</td>\n",
       "      <td>1 opinión</td>\n",
       "      <td>Escribió una opinión el 10 de marzo de 2020</td>\n",
       "      <td>Mala calidad y costo alto</td>\n",
       "      <td>Mala calidad de la carne no es la mamona tradi...</td>\n",
       "      <td>marzo de 2020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asadero Cimarron del Llano</td>\n",
       "      <td>/Restaurant_Review-g294074-d10003846-Reviews-A...</td>\n",
       "      <td>4,0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>4.666695</td>\n",
       "      <td>-74.113075</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Comida para llevar, Servicio de mesa, Reservas...</td>\n",
       "      <td>HectorLatorre</td>\n",
       "      <td>55 opiniones</td>\n",
       "      <td>Escribió una opinión el 13 de febrero de 2020</td>\n",
       "      <td>Maravilloso sitio de comida llanera</td>\n",
       "      <td>Este es un restaurante bastante típico y muy b...</td>\n",
       "      <td>enero de 2020</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asadero Cimarron del Llano</td>\n",
       "      <td>/Restaurant_Review-g294074-d10003846-Reviews-A...</td>\n",
       "      <td>4,0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>4.666695</td>\n",
       "      <td>-74.113075</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Comida para llevar, Servicio de mesa, Reservas...</td>\n",
       "      <td>Ingriofercas</td>\n",
       "      <td>1 opinión</td>\n",
       "      <td>Escribió una opinión el 13 de enero de 2020</td>\n",
       "      <td>Buen Restaurante Tipico!!!</td>\n",
       "      <td>buen servicio, eramos mas o menos 20 personas ...</td>\n",
       "      <td>diciembre de 2019</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asadero Cimarron del Llano</td>\n",
       "      <td>/Restaurant_Review-g294074-d10003846-Reviews-A...</td>\n",
       "      <td>4,0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>4.666695</td>\n",
       "      <td>-74.113075</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Comida para llevar, Servicio de mesa, Reservas...</td>\n",
       "      <td>profet2016</td>\n",
       "      <td>429 opiniones</td>\n",
       "      <td>Escribió una opinión el 12 de octubre de 2019</td>\n",
       "      <td>Un recuerdo de la cultura llanera</td>\n",
       "      <td>Muy buen ambiente, buena comida y muy buena mú...</td>\n",
       "      <td>octubre de 2019</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nombre  \\\n",
       "0  Asadero Cimarron del Llano   \n",
       "1  Asadero Cimarron del Llano   \n",
       "2  Asadero Cimarron del Llano   \n",
       "3  Asadero Cimarron del Llano   \n",
       "4  Asadero Cimarron del Llano   \n",
       "\n",
       "                                                link puntaje_global  \\\n",
       "0  /Restaurant_Review-g294074-d10003846-Reviews-A...            4,0   \n",
       "1  /Restaurant_Review-g294074-d10003846-Reviews-A...            4,0   \n",
       "2  /Restaurant_Review-g294074-d10003846-Reviews-A...            4,0   \n",
       "3  /Restaurant_Review-g294074-d10003846-Reviews-A...            4,0   \n",
       "4  /Restaurant_Review-g294074-d10003846-Reviews-A...            4,0   \n",
       "\n",
       "   n_comentarios  posicion_relativa  n_restaurantes       lat        lon  \\\n",
       "0           17.0               83.0           127.0  4.666695 -74.113075   \n",
       "1           17.0               83.0           127.0  4.666695 -74.113075   \n",
       "2           17.0               83.0           127.0  4.666695 -74.113075   \n",
       "3           17.0               83.0           127.0  4.666695 -74.113075   \n",
       "4           17.0               83.0           127.0  4.666695 -74.113075   \n",
       "\n",
       "   excelente  muy_bueno  ...  \\\n",
       "0        9.0        3.0  ...   \n",
       "1        9.0        3.0  ...   \n",
       "2        9.0        3.0  ...   \n",
       "3        9.0        3.0  ...   \n",
       "4        9.0        3.0  ...   \n",
       "\n",
       "                                     características            usuario  \\\n",
       "0  Comida para llevar, Servicio de mesa, Reservas...          Marylyn73   \n",
       "1  Comida para llevar, Servicio de mesa, Reservas...  jairoenriquer2020   \n",
       "2  Comida para llevar, Servicio de mesa, Reservas...      HectorLatorre   \n",
       "3  Comida para llevar, Servicio de mesa, Reservas...       Ingriofercas   \n",
       "4  Comida para llevar, Servicio de mesa, Reservas...         profet2016   \n",
       "\n",
       "   relevancia_usuario                               fecha_comentario  \\\n",
       "0         4 opiniones     Escribió una opinión el 6 de enero de 2021   \n",
       "1           1 opinión    Escribió una opinión el 10 de marzo de 2020   \n",
       "2        55 opiniones  Escribió una opinión el 13 de febrero de 2020   \n",
       "3           1 opinión    Escribió una opinión el 13 de enero de 2020   \n",
       "4       429 opiniones  Escribió una opinión el 12 de octubre de 2019   \n",
       "\n",
       "                     titulo_comentario  \\\n",
       "0                   Comida recalentada   \n",
       "1            Mala calidad y costo alto   \n",
       "2  Maravilloso sitio de comida llanera   \n",
       "3           Buen Restaurante Tipico!!!   \n",
       "4    Un recuerdo de la cultura llanera   \n",
       "\n",
       "                                contenido_comentario       fecha_visita  \\\n",
       "0  Fui temprano para evitar aglomeraciones y me t...      enero de 2021   \n",
       "1  Mala calidad de la carne no es la mamona tradi...      marzo de 2020   \n",
       "2  Este es un restaurante bastante típico y muy b...      enero de 2020   \n",
       "3  buen servicio, eramos mas o menos 20 personas ...  diciembre de 2019   \n",
       "4  Muy buen ambiente, buena comida y muy buena mú...    octubre de 2019   \n",
       "\n",
       "  puntaje rango_de_precios dietas_especiales  \n",
       "0    10.0              NaN               NaN  \n",
       "1    10.0              NaN               NaN  \n",
       "2    40.0              NaN               NaN  \n",
       "3    50.0              NaN               NaN  \n",
       "4    50.0              NaN               NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/comentarios_tripadvisor.csv\", sep = \";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En total tenemos más de 130 mil comentarios (los cuales representan cada una de las filas del dataframe) y 25 variables que describen el restaurante y el comentario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132728, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a quedarnos solo con las columnas que nos interesan: `titulo_comentario` y `contenido_comentario`. Luego las unimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a reducir el tamaño de nuestra muestra para facilitar le computo de\n",
    "# los procesos\n",
    "# df = df.sample(10000, random_state = 666).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comentarios = df[\"titulo_comentario\"] + \" \" + df[\"contenido_comentario\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a preprocesar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import re\n",
    "\n",
    "# Convertimos la columna en texto\n",
    "comentarios = comentarios.astype(str)\n",
    "\n",
    "# Quitamos tildes\n",
    "comentarios = comentarios.apply(lambda x: unidecode.unidecode(x))\n",
    "\n",
    "# Quitamos comas, guiones y otros caracteres especiales o signos de puntuación\n",
    "comentarios = comentarios.apply(lambda x:\n",
    "    re.sub('[^A-Za-z0-9 ]+', ' ', x))\n",
    "\n",
    "# Ponemos todo el texto en minúscula \n",
    "comentarios = comentarios.str.lower()\n",
    "\n",
    "# Dejamos todos los espacios sencillos\n",
    "comentarios = comentarios.apply(lambda x: \n",
    "    re.sub('\\s+', ' ', x))\n",
    "\n",
    "# Vamos a eliminar todos los números\n",
    "comentarios = comentarios.apply(lambda x: re.sub(\"\\d+\", \"\", x))\n",
    "comentarios = comentarios.apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "comentarios = comentarios.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words(\"spanish\"))\n",
    "\n",
    "# Creamos un diccionario de stopwords en español\n",
    "stopwords = [unidecode.unidecode(i) for i in stopwords]\n",
    "stopwords = set(stopwords)\n",
    "\n",
    "# Creamos una función que elimine las palabras presentes en un diccionario\n",
    "def eliminar_stopwords(texto, diccionario):\n",
    "    texto = [tok for tok in texto.split(\" \") if tok not in diccionario]\n",
    "    return(texto)\n",
    "\n",
    "# Aplicamos la función para eliminar los stopwords\n",
    "comentarios = comentarios.apply(lambda x: \n",
    "    eliminar_stopwords(x, stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizamos el texto\n",
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Esto puede tardar un poco\n",
    "comentarios = comentarios.apply(lambda x: nlp(\" \".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizamos el texto\n",
    "comentarios = comentarios.apply(lambda x: [unidecode.unidecode(tok.lemma_) for tok in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buen', 86367),\n",
       " ('comida', 69954),\n",
       " ('excelente', 51889),\n",
       " ('lugar', 49806),\n",
       " ('servicio', 47345),\n",
       " ('restaurante', 44469),\n",
       " ('atencion', 35712),\n",
       " ('plato', 32503),\n",
       " ('mejor', 30294),\n",
       " ('ambiente', 29256)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para aplicar LDA necesitamos construir un diccionario\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "# A cada palabra se le asigna un id\n",
    "diccionario = corpora.Dictionary(comentarios)\n",
    "\n",
    "diccionario.most_common()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un corpus\n",
    "textos = comentarios.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencias \n",
    "corpus = [diccionario.doc2bow(texto) for texto in textos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.035*\"buen\" + 0.028*\"comida\" + 0.025*\"excelente\" + 0.021*\"atencion\" + '\n",
      "  '0.021*\"restaurante\" + 0.015*\"plato\" + 0.014*\"ambiente\" + 0.013*\"servicio\" + '\n",
      "  '0.010*\"sabor\" + 0.009*\"agradable\"'),\n",
      " (1,\n",
      "  '0.029*\"lugar\" + 0.029*\"buen\" + 0.020*\"comida\" + 0.019*\"excelente\" + '\n",
      "  '0.016*\"mejor\" + 0.015*\"servicio\" + 0.012*\"ambiente\" + 0.012*\"bogota\" + '\n",
      "  '0.012*\"restaurante\" + 0.009*\"delicioso\"'),\n",
      " (2,\n",
      "  '0.023*\"buen\" + 0.021*\"comida\" + 0.019*\"servicio\" + 0.013*\"restaurante\" + '\n",
      "  '0.010*\"plato\" + 0.009*\"precio\" + 0.009*\"atencion\" + 0.008*\"lugar\" + '\n",
      "  '0.007*\"bien\" + 0.007*\"calidad\"')]\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos LDA\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from pprint import pprint\n",
    "\n",
    "# Debemos escoger el número de tópicos antes de correr el modelo\n",
    "n_topicos = 3\n",
    "# Modelo LDA\n",
    "lda_model = LdaMulticore(corpus = corpus,\n",
    "    id2word = diccionario,\n",
    "    num_topics = n_topicos)\n",
    "# Mostramos las palabras dentro de los 10 tópicos\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VISUALIZACION\n",
    "\n",
    "La salida de los modelos LDA en Python usando sklearn puede ser difícil de interpretar en forma cruda. Como es el caso en la mayoría de los ejercicios de modelado, las visualizaciones pueden ser un gran beneficio cuando se trata de interpretar y comunicar los resultados del modelo. Una librería de Python, pyLDAvis, se integra directamente con el objeto del modelo sklearn para producir gráficos sencillos. Esta herramienta de visualización devuelve un histograma que muestra las palabras más relacionadas con cada tópico y un biplot, de uso frecuente en PCA, donde cada círculo corresponde a un tópico. A partir del biplot, sabemos la prevalencia de cada tópico en todo el corpus, lo que se refleja en el área del círculo, y la similitud de los tópicos, que se refleja en la cercanía de los círculos.\n",
    "\n",
    "\n",
    "El escenario ideal es que los círculos se extiendan por toda la trama y tengan un tamaño razonable y consistente. Es decir, queremos que los tópicos sean distintos y que aparezcan uniformemente en todo el corpus. Además de los gráficos de pyLDAvis, aprovecharemos el modelo t-SNE, discutido en un capítulo anterior, para producir una representación bidimensional de la matriz tópico-documento, una matriz donde cada fila representa un documento y cada columna representa la probabilidad de ese tópico que describe el documento.\n",
    "\n",
    "Habiendo completado el ajuste del modelo LDA, creemos algunos gráficos para ayudarnos a profundizar en los resultados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/joblib/backports.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) < '1.13':\n",
      "/Users/iggy/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "# Visualizamos los resultados\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "LDA_visualization = gensimvis.prepare(lda_model, corpus, diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el201621406717999771204876707238\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el201621406717999771204876707238_data = {\"mdsDat\": {\"x\": [-0.02794195606124254, 0.05133291770195788, -0.023390961640715312], \"y\": [0.02804096894208179, 0.001707811402782907, -0.029748780344864723], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [39.02246527461792, 31.723365193620378, 29.254169531761693]}, \"tinfo\": {\"Term\": [\"excelente\", \"lugar\", \"atencion\", \"ambiente\", \"restaurante\", \"bogota\", \"cumpleano\", \"pesimo\", \"esperar\", \"comida\", \"buen\", \"mejor\", \"malo\", \"mal\", \"plato\", \"sabor\", \"delicioso\", \"mesero\", \"italiano\", \"espectacular\", \"super\", \"minuto\", \"agradable\", \"exquisito\", \"peor\", \"mesa\", \"tipico\", \"celebrar\", \"perfecto\", \"llegar\", \"tatiana\", \"fire\", \"tertuliar\", \"cotta\", \"big\", \"teo\", \"gaston\", \"rumbo\", \"fabricar\", \"mandarino\", \"mozos\", \"chateaubriand\", \"stephany\", \"bucco\", \"gaira\", \"felicitacionesma\", \"desfile\", \"acristalado\", \"entradita\", \"intrigante\", \"cafecito\", \"escargot\", \"chocolo\", \"bon\", \"baguettir\", \"dry\", \"parejama\", \"hard\", \"monteria\", \"astrid\", \"nar\", \"chorro\", \"vives\", \"quevedo\", \"this\", \"z\", \"fi\", \"was\", \"lugar\", \"bicono\", \"nueva\", \"bogota\", \"disfrutar\", \"precioso\", \"place\", \"mejor\", \"saludable\", \"sano\", \"best\", \"compartir\", \"delicioso\", \"cafe\", \"genial\", \"opcion\", \"amigo\", \"artesanal\", \"ciudad\", \"rumba\", \"colombia\", \"menu\", \"obligado\", \"encarecidamente\", \"vegetarian\", \"vegetariano\", \"gran\", \"zona\", \"sabroso\", \"recomendado\", \"ambiente\", \"encantador\", \"acogedor\", \"dudar\", \"excelente\", \"fantastico\", \"comer\", \"diferente\", \"buen\", \"increible\", \"delicios\", \"siempre\", \"recomeir\", \"probar\", \"comido\", \"bien\", \"comida\", \"servicio\", \"agradable\", \"ir\", \"experiencia\", \"restaurante\", \"carne\", \"precio\", \"plato\", \"bueno\", \"poder\", \"sitio\", \"atencion\", \"sabor\", \"extravagante\", \"domino\", \"esfero\", \"enano\", \"estricto\", \"todoma\", \"disculpar el\", \"once\", \"discapacidad\", \"obligatoriamente\", \"falencia\", \"centimetro\", \"esforzar el\", \"estomacal\", \"seguiar\", \"reforma\", \"johan\", \"yasai\", \"kibbe\", \"restrepo\", \"asemejo\", \"carinoso\", \"comence\", \"racista\", \"servcio\", \"ignoro\", \"chatear\", \"identificacion\", \"carente\", \"lentisimo\", \"mantenimiento\", \"empeorar\", \"peor\", \"groserio\", \"minuto\", \"lamentable\", \"deficiente\", \"eternidad\", \"pesimo\", \"decepcionante\", \"terrible\", \"horrible\", \"malisimo\", \"demorar\", \"mediocre\", \"traerno\", \"lento\", \"mal\", \"malo\", \"mala\", \"orden\", \"pedido\", \"esperar\", \"demoro\", \"min\", \"grosero\", \"nadie\", \"desmejorado\", \"domicilio\", \"llego\", \"cara\", \"aceptable\", \"actitud\", \"nunca\", \"pagar\", \"demasiado\", \"demorado\", \"regular\", \"ver\", \"mesero\", \"mesa\", \"despu\", \"llegar\", \"servicio\", \"calidad\", \"frio\", \"pedir\", \"asi\", \"comida\", \"ir\", \"precio\", \"ser\", \"buen\", \"hora\", \"persona\", \"decir\", \"hacer\", \"restaurante\", \"comido\", \"plato\", \"bueno\", \"vez\", \"bien\", \"atencion\", \"solo\", \"sitio\", \"lugar\", \"rico\", \"mejor\", \"poder\", \"excelente\", \"sabor\", \"ronald\", \"jessico\", \"anti\", \"souvenirs\", \"arquitecturo\", \"motor\", \"sumo\", \"arigato\", \"edificacion\", \"enhorabuena\", \"barroco\", \"simbolo\", \"fernandez\", \"coqueto\", \"italianisimo\", \"nombrado\", \"informalidad\", \"pianista\", \"friends\", \"experencia\", \"dw\", \"katherine\", \"ceramico\", \"pastelero\", \"camila\", \"antioquen\", \"puchero\", \"terracitar\", \"gris\", \"muchacha\", \"sebastian\", \"huesito\", \"rocio\", \"marrano\", \"talla\", \"mariachis\", \"gracia\", \"vistas\", \"cumpleano\", \"ambientar\", \"laura\", \"italiano\", \"cavo\", \"trattoria\", \"gabriel\", \"danielar\", \"celebrar\", \"atencion\", \"celebracion\", \"exquisito\", \"esmerado\", \"tipico\", \"cartar\", \"tematico\", \"excelente\", \"mil\", \"paisa\", \"vino\", \"amplio\", \"restaurante\", \"sabor\", \"ambiente\", \"espectacular\", \"buen\", \"plato\", \"carta\", \"comida\", \"super\", \"aniversario\", \"especial\", \"agradable\", \"sazon\", \"presentacion\", \"sitio\", \"gusto\", \"perfecto\", \"dar\", \"rico\", \"delicios\", \"servicio\", \"hacer\", \"musico\", \"experiencia\", \"bien\", \"precio\", \"recomendado\", \"poder\", \"delicioso\", \"bueno\", \"lugar\", \"mejor\", \"comido\", \"carne\", \"bogota\"], \"Freq\": [50007.0, 47524.0, 34972.0, 28162.0, 44856.0, 19980.0, 5639.0, 4629.0, 7213.0, 68991.0, 86140.0, 29923.0, 5790.0, 4862.0, 32747.0, 19310.0, 16866.0, 7149.0, 4034.0, 8021.0, 8974.0, 2580.0, 18876.0, 4274.0, 2028.0, 8239.0, 4343.0, 3334.0, 5687.0, 6542.0, 42.56486045436641, 31.568029948981227, 22.968344866169204, 18.477956795120658, 33.804926966584624, 44.31570790465631, 45.72341921774907, 59.5847906097537, 17.482141187794284, 28.953466038218846, 17.372008955337712, 36.09338348876436, 19.101465539190215, 21.09531742943567, 134.65477827447583, 14.03551668632724, 17.09911319401201, 15.8343078159878, 16.405028938361998, 12.952693210467027, 14.99610021536137, 25.913641680731445, 46.31294969795216, 24.14913182901292, 12.823522485862927, 24.318853974409063, 14.277538204299141, 203.81056505092786, 20.404952858939506, 30.359663351654863, 865.3777742231309, 97.16381249436753, 123.5730802720659, 80.49390963727413, 50.359371824394955, 56.541809766419, 37.3220188367995, 49.59073539894302, 33894.58480135217, 78.57252201065616, 62.75619802651752, 14135.608492782949, 3789.9473467293465, 680.9987073635839, 58.622280853433516, 19236.237993998126, 801.2561412360292, 343.7672630512172, 125.82241692758447, 3436.899792577064, 10543.274668526496, 2024.7408238929577, 2822.3548001838753, 8682.996882016932, 4635.694914053673, 984.4031078940126, 2919.4231900124655, 707.2252415928955, 2280.1665710182165, 5736.9216789013235, 633.5416750226135, 298.31657363302094, 607.6706544665896, 962.5253117565491, 6996.889547493293, 3013.4328465486756, 1934.0021946660597, 7375.715269266499, 14203.484468024948, 827.9324125967569, 3566.1466925641766, 1335.7181838874558, 22119.607931149218, 1540.6944301677354, 5395.473409338489, 3836.5593830978205, 33577.22210347151, 3717.840018692789, 7625.020534656338, 4600.207687202586, 5026.500651713316, 3460.6139525188382, 8617.211228496206, 9654.247080417725, 23620.839384215906, 17166.32061955551, 8274.65228707203, 6657.543112045162, 6369.5337281545035, 13946.170414272643, 5913.233984274349, 8356.12056148981, 10318.577966406063, 6887.188498712654, 5929.721924502258, 6111.15285927773, 7814.919657113035, 6185.242785925613, 39.56867493670468, 21.67021218739903, 23.001721912456347, 21.33387256449364, 20.624531951608507, 18.41746856068203, 19.508577277112902, 20.927376883288744, 16.703041745789537, 19.085903520775194, 14.498816002820282, 13.726244585361927, 15.32051354770497, 15.879089750533929, 19.116355139221678, 15.408075007400996, 18.42350944314311, 14.057071685410538, 16.02672230250725, 17.465714472275636, 12.810794981924838, 12.39724435081402, 18.410395331448772, 10.93803350412833, 16.878845352513665, 19.55775911296539, 10.633331915057676, 10.278916648753595, 16.449580593006594, 17.102164764970603, 38.132107824362315, 17.589469000088656, 1750.9406799814897, 32.897124346681935, 2176.254124384086, 143.21985968344268, 364.02317321891854, 71.96212547542085, 3663.5374079791804, 703.8069417170735, 1019.9437367524006, 649.7032524867666, 212.64868626082534, 575.7606785344609, 364.93784986794276, 54.23715965581887, 1517.4053867008788, 3614.6773300690543, 4255.588511614902, 512.8727732513229, 838.8871736196077, 1925.9082564272132, 4988.189077599263, 649.6238122710708, 241.90406374539776, 345.0184386159382, 555.3907810943612, 186.15806225785485, 1064.6084130888612, 1217.7913209038752, 583.7824133585208, 659.0038856500462, 587.3004561785784, 2025.924713573537, 1491.9222356577986, 2334.037545447758, 1131.992322613192, 1998.6471941240334, 2990.8269654497526, 4019.598259410532, 4539.588285478877, 2060.123893555836, 3647.101193926674, 18147.80865101306, 6717.573827747832, 1392.3278255480184, 5294.301976974552, 3239.1568568809607, 20549.057521280924, 6216.435533090035, 8463.309669473745, 4195.534828220781, 22080.75401337682, 2248.67998072592, 2869.880629763628, 3122.6792283072136, 5717.427528648372, 12117.111250064529, 6668.99875414591, 9226.286034736595, 5951.098973322503, 4487.288769337997, 6770.920216633001, 8358.512760862284, 3430.121999231653, 5019.981653571705, 7555.251627144061, 4429.705866060662, 5664.983170599491, 4198.682577132192, 5603.0104433412125, 4262.420592998441, 40.333457530172886, 39.098607568361764, 33.15935735252844, 31.478990338665223, 20.789841628100366, 23.56300282502144, 62.9777526096044, 18.324911305873535, 17.252963058231177, 22.933253296854822, 21.68975993756376, 16.3046279165617, 50.869084796159484, 13.788644718543706, 15.243334614884118, 15.550284391660641, 14.88538172927815, 71.21250875073929, 12.670345770299402, 12.34571828710565, 17.90192423900597, 39.042358058535946, 19.554463494340713, 11.095037615311298, 10.505304737828888, 18.499696086191356, 18.782884546827347, 9.746623460329241, 101.62122686460188, 20.78020610215783, 64.7762728121245, 31.57317832717714, 119.31199470120505, 87.03698341528053, 31.56777780913804, 239.12150490252594, 1370.160101819398, 67.90493225966885, 4021.8946512528373, 45.912860505083316, 205.11373001898073, 2800.3771493191553, 136.25328493745428, 77.35968533262148, 84.34220839383366, 71.71677971456161, 2169.0629864054554, 18799.354688420874, 1500.5138377333815, 2610.376932781958, 375.1139724313284, 2576.268570841856, 2036.4604773486076, 508.48046535517744, 22284.661881394804, 941.4080301066701, 393.65353345924007, 2951.3343816973306, 1752.4585227456362, 18793.267270722314, 8863.15029981228, 12060.587405900027, 4015.8725791803936, 30482.352051794853, 13202.683463968036, 2887.423277012305, 24821.670060302687, 4241.875975325747, 842.8334338936179, 3295.2373155334153, 7568.494808589843, 780.861018861478, 2113.311659920275, 7035.101888372702, 3392.8620370397566, 2598.0872288156497, 2655.2868445237395, 5206.572631759798, 5281.595986204653, 11346.387658978798, 5088.841184390341, 3917.027661674388, 4563.74962456297, 5805.5980412845975, 5709.802586330801, 4199.639686041298, 4311.22247987388, 4516.036632047962, 4247.472684360248, 6075.096965698224, 5022.55112903369, 4010.8278146482676, 3543.187389542726, 3394.0814110818596], \"Total\": [50007.0, 47524.0, 34972.0, 28162.0, 44856.0, 19980.0, 5639.0, 4629.0, 7213.0, 68991.0, 86140.0, 29923.0, 5790.0, 4862.0, 32747.0, 19310.0, 16866.0, 7149.0, 4034.0, 8021.0, 8974.0, 2580.0, 18876.0, 4274.0, 2028.0, 8239.0, 4343.0, 3334.0, 5687.0, 6542.0, 43.52961120994915, 32.34756804574789, 23.775456568849776, 19.22000008589669, 35.35425124443736, 46.35639070684786, 47.84469052103316, 62.4254419840666, 18.35026656365083, 30.413306495499835, 18.28698206160239, 37.99639895153789, 20.140313420402382, 22.262665260983233, 142.2339659778994, 14.830824845127195, 18.078049081989814, 16.76468319263116, 17.38309986296796, 13.72654868891238, 15.907817550298912, 27.489763177921215, 49.13605736213873, 25.660747664264807, 13.641263532450932, 25.870887243596712, 15.195368656646446, 217.45243773345848, 21.77133864594961, 32.41419483620896, 934.8135130691484, 104.39326067424167, 133.25976620459062, 86.59178335118602, 54.33323666269978, 61.39996048497502, 40.379163811503396, 54.26571967743966, 47524.93339419446, 87.47284967308119, 69.2259194629554, 19980.941766113778, 5124.46169147194, 859.0524101936827, 65.03497933307999, 29923.772293631308, 1035.1827359111712, 423.80582881837705, 146.9760169235275, 4974.73690301845, 16866.758485623133, 2884.338240328621, 4123.724498515268, 14017.35443919829, 7178.79523589636, 1342.6530576439575, 4421.541618182391, 947.3111932701487, 3441.9495901231835, 9545.701182646557, 849.0577873807508, 374.98691346998675, 820.0364063091346, 1361.013424865059, 12211.381980709193, 4793.777804108537, 2963.56098247564, 13351.837503013532, 28162.376828026536, 1158.4975278779043, 6005.788571776488, 1982.9280877169929, 50007.280255885235, 2349.041056704773, 9962.92269993224, 6751.575201946043, 86140.32816864319, 6542.837604278029, 15589.417559581323, 8643.039507868636, 9654.814916277452, 6181.987873071312, 19297.037797290384, 22230.76533833532, 68991.56696579952, 46660.51692954737, 18876.85239105503, 14886.303982613039, 14211.332713067364, 44856.54893505949, 12787.308393704494, 22529.232817294353, 32747.547465110692, 17085.760156395405, 14439.626981508329, 18166.236401222137, 34972.787106396194, 19310.813678736333, 40.59407487235175, 22.41308967515583, 23.836066762757362, 22.125932034149795, 21.469237329596982, 19.18167645574032, 20.385016905246626, 21.880029377167514, 17.46944422443649, 19.99936401705636, 15.252926630478251, 14.453153714056294, 16.197086017818695, 16.78946741726862, 20.231299937846654, 16.309456702916876, 19.501870401459502, 14.880928277062639, 16.97275226123449, 18.518521721007918, 13.588135335004875, 13.157872994190068, 19.540323599135963, 11.624068095852452, 17.948721220371038, 20.856982485659405, 11.3505503767712, 10.983767819526705, 17.58919926231969, 18.310067125106134, 41.14063173633598, 18.846997125925448, 2028.2733101589215, 35.542279446083036, 2580.607997979991, 162.08468849034753, 424.0602973170514, 80.28667582475788, 4629.743071409076, 849.8621626928033, 1258.6428725813953, 787.7582802985386, 246.4392568972359, 697.8496469337636, 434.58220384702247, 60.08936418139183, 1941.573853648804, 4862.638833792418, 5790.394781072288, 636.2811680681898, 1075.2628802081406, 2582.2515689005677, 7213.351492311768, 826.3419247131794, 291.18421739447814, 425.7482894543193, 709.1995275759137, 222.1243473184594, 1448.0168425021213, 1715.824700209579, 775.9642664926052, 887.1840550733357, 782.8779935591701, 3029.4256354643962, 2168.40096668103, 3555.5447408978334, 1640.276622416192, 3122.450745076315, 5079.2020769417595, 7149.155803100955, 8239.798803087866, 3337.786992676986, 6542.700739185801, 46660.51692954737, 14527.843894489055, 2156.5278492331336, 11339.83049277294, 6225.9012958043895, 68991.56696579952, 14886.303982613039, 22529.232817294353, 9112.869897045373, 86140.32816864319, 4072.026106181297, 5711.240630662037, 6426.751516997372, 15272.511337680324, 44856.54893505949, 19297.037797290384, 32747.547465110692, 17085.760156395405, 11301.336045119791, 22230.76533833532, 34972.787106396194, 7870.32105329143, 18166.236401222137, 47524.93339419446, 14657.918726669675, 29923.772293631308, 14439.626981508329, 50007.280255885235, 19310.813678736333, 41.365285121281346, 40.138771875619575, 34.3607211780697, 32.62950457594774, 21.573904036890056, 24.47678458349284, 65.50797300910172, 19.093883618362344, 17.992148333568743, 23.943835829569082, 22.661294037111094, 17.085081488831282, 53.307805483251485, 14.502291845644272, 16.06338345050939, 16.39235296372935, 15.754226170699381, 75.52182659118814, 13.454972140299416, 13.129182984814465, 19.042183573712627, 41.713933586999254, 20.907714319372676, 11.881548400479975, 11.2520779679953, 19.865963182675472, 20.17199098083321, 10.467877474376674, 109.1903279690358, 22.417666890253443, 70.43902235889956, 34.105093912958885, 130.78364112467742, 97.44928169219777, 34.38953819611159, 277.62409395418587, 1738.632220980894, 76.32521132367604, 5639.220975125256, 51.06882429161131, 247.85004615125766, 4034.259147743963, 162.7561525611296, 89.28134681205815, 97.94328501402593, 82.67063950262467, 3334.95171069324, 34972.787106396194, 2300.0430822936705, 4274.003163930514, 514.7815453714518, 4343.679943830524, 3400.3265459651398, 729.3597959215964, 50007.280255885235, 1456.3081939698282, 548.8664868501518, 5287.717190119702, 2949.4730970250375, 44856.54893505949, 19310.813678736333, 28162.376828026536, 8021.700673662949, 86140.32816864319, 32747.547465110692, 5621.922412660189, 68991.56696579952, 8974.779522485558, 1365.2255917314596, 6805.106401106151, 18876.85239105503, 1251.5013648753375, 4188.033336341578, 18166.236401222137, 7844.632024692792, 5687.163387525906, 5854.3485622744265, 14657.918726669675, 15589.417559581323, 46660.51692954737, 15272.511337680324, 10404.825233178917, 14211.332713067364, 22230.76533833532, 22529.232817294353, 13351.837503013532, 14439.626981508329, 16866.758485623133, 17085.760156395405, 47524.93339419446, 29923.772293631308, 19297.037797290384, 12787.308393704494, 19980.941766113778], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -10.2277, -10.5266, -10.8446, -11.0621, -10.4581, -10.1874, -10.1561, -9.8913, -11.1175, -10.613, -11.1238, -10.3926, -11.0289, -10.9297, -9.076, -11.3371, -11.1397, -11.2165, -11.1811, -11.4174, -11.2709, -10.7239, -10.1433, -10.7945, -11.4274, -10.7875, -11.32, -8.6615, -10.9629, -10.5656, -7.2155, -9.4023, -9.1619, -9.5905, -10.0595, -9.9437, -10.3591, -10.0749, -3.5477, -9.6147, -9.8395, -4.4223, -5.7386, -7.4551, -9.9076, -4.1142, -7.2925, -8.1387, -9.1438, -5.8364, -4.7155, -6.3655, -6.0334, -4.9096, -5.5372, -7.0867, -5.9996, -7.4174, -6.2467, -5.324, -7.5274, -8.2806, -7.5691, -7.1091, -5.1255, -5.9679, -6.4114, -5.0728, -4.4175, -7.2598, -5.7995, -6.7815, -3.9745, -6.6387, -5.3854, -5.7264, -3.5571, -5.7578, -5.0395, -5.5449, -5.4562, -5.8295, -4.9172, -4.8036, -3.9088, -4.228, -4.9578, -5.1752, -5.2194, -4.4357, -5.2938, -4.948, -4.737, -5.1413, -5.291, -5.2608, -5.0149, -5.2488, -10.0936, -10.6957, -10.6361, -10.7113, -10.7451, -10.8583, -10.8008, -10.7306, -10.956, -10.8227, -11.0976, -11.1523, -11.0424, -11.0066, -10.8211, -11.0367, -10.858, -11.1285, -10.9974, -10.9114, -11.2213, -11.2542, -10.8587, -11.3794, -10.9456, -10.7983, -11.4076, -11.4415, -10.9713, -10.9324, -10.1306, -10.9043, -6.3037, -10.2782, -6.0863, -8.8072, -7.8744, -9.4955, -5.5654, -7.2151, -6.8441, -7.2951, -8.412, -7.4159, -7.8719, -9.7783, -6.4469, -5.5789, -5.4156, -7.5316, -7.0395, -6.2085, -5.2568, -7.2952, -8.2831, -7.928, -7.452, -8.545, -6.8013, -6.6668, -7.4021, -7.2809, -7.3961, -6.1578, -6.4638, -6.0163, -6.7399, -6.1714, -5.7683, -5.4727, -5.351, -6.1411, -5.5699, -3.9653, -4.9591, -6.5329, -5.1972, -5.6886, -3.8411, -5.0367, -4.7281, -5.4298, -3.7692, -6.0535, -5.8096, -5.7252, -5.1204, -4.3693, -4.9664, -4.6418, -5.0803, -5.3626, -4.9512, -4.7406, -5.6313, -5.2504, -4.8416, -5.3755, -5.1296, -5.4291, -5.1406, -5.414, -9.9934, -10.0245, -10.1893, -10.2413, -10.6561, -10.5309, -9.5478, -10.7823, -10.8426, -10.558, -10.6138, -10.8991, -9.7613, -11.0667, -10.9665, -10.9465, -10.9902, -9.4249, -11.1513, -11.1773, -10.8057, -10.0259, -10.7174, -11.2841, -11.3387, -10.7728, -10.7576, -11.4137, -9.0693, -10.6566, -9.5197, -10.2383, -8.9089, -9.2243, -10.2385, -8.2136, -6.4679, -9.4725, -5.3911, -9.8638, -8.367, -5.7531, -8.7761, -9.3421, -9.2557, -9.4179, -6.0085, -3.849, -6.377, -5.8233, -7.7634, -5.8365, -6.0716, -7.4592, -3.6789, -6.8432, -7.7151, -5.7006, -6.2218, -3.8493, -4.6009, -4.2929, -5.3926, -3.3657, -4.2024, -5.7225, -3.5711, -5.3378, -6.9538, -5.5904, -4.7588, -7.0302, -6.0346, -4.8319, -5.5612, -5.8281, -5.8063, -5.1329, -5.1186, -4.3539, -5.1558, -5.4175, -5.2647, -5.024, -5.0407, -5.3478, -5.3216, -5.2752, -5.3365, -4.9786, -5.1689, -5.3938, -5.5178, -5.5608], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9186, 0.9166, 0.9065, 0.9017, 0.8962, 0.896, 0.8957, 0.8945, 0.8926, 0.8918, 0.8897, 0.8897, 0.8881, 0.8872, 0.8863, 0.8859, 0.8854, 0.8839, 0.8831, 0.883, 0.882, 0.882, 0.8819, 0.8803, 0.8792, 0.8792, 0.8787, 0.8762, 0.8762, 0.8756, 0.8639, 0.8693, 0.8656, 0.868, 0.8651, 0.8586, 0.8623, 0.8509, 0.603, 0.8337, 0.8429, 0.595, 0.6394, 0.7088, 0.8372, 0.4992, 0.6849, 0.7317, 0.7856, 0.5712, 0.4712, 0.5872, 0.5618, 0.4621, 0.5037, 0.6307, 0.5259, 0.6488, 0.5292, 0.4319, 0.6482, 0.7123, 0.6413, 0.5946, 0.3841, 0.4768, 0.5142, 0.3476, 0.2565, 0.6051, 0.4198, 0.5459, 0.1253, 0.5193, 0.3277, 0.3758, -0.0011, 0.3758, 0.2259, 0.3104, 0.2883, 0.3608, 0.1348, 0.107, -0.1308, -0.0589, 0.1163, 0.1363, 0.1385, -0.2272, 0.1698, -0.0508, -0.2138, 0.0325, 0.051, -0.1484, -0.5575, -0.1975, 1.1225, 1.1144, 1.1125, 1.1117, 1.108, 1.1075, 1.1042, 1.1036, 1.1033, 1.1014, 1.0974, 1.0965, 1.0925, 1.0924, 1.0914, 1.0913, 1.0912, 1.0912, 1.0908, 1.0896, 1.0892, 1.0886, 1.0886, 1.0873, 1.0867, 1.0838, 1.0828, 1.0818, 1.0811, 1.0799, 1.0722, 1.0791, 1.0011, 1.0708, 0.9777, 1.0244, 0.9955, 1.0387, 0.914, 0.9595, 0.9378, 0.9554, 1.0006, 0.9558, 0.9735, 1.0457, 0.9016, 0.8515, 0.8401, 0.9325, 0.8999, 0.8549, 0.7793, 0.9075, 0.9627, 0.9379, 0.9037, 0.9715, 0.8405, 0.8053, 0.8635, 0.8508, 0.8607, 0.7458, 0.7742, 0.7272, 0.7772, 0.702, 0.6185, 0.5723, 0.552, 0.6656, 0.5637, 0.2038, 0.3768, 0.7106, 0.3864, 0.4947, -0.0631, 0.2749, 0.169, 0.3724, -0.2132, 0.5543, 0.46, 0.4263, 0.1656, -0.1607, 0.0856, -0.1187, 0.0934, 0.2244, -0.0407, -0.2832, 0.3176, -0.138, -0.6909, -0.0485, -0.5162, -0.0871, -1.0407, -0.3627, 1.2039, 1.2029, 1.1936, 1.1933, 1.1921, 1.1911, 1.1898, 1.188, 1.1872, 1.186, 1.1853, 1.1824, 1.1823, 1.1787, 1.1767, 1.1764, 1.1724, 1.1704, 1.1691, 1.1676, 1.1674, 1.163, 1.1622, 1.1607, 1.1605, 1.1579, 1.1578, 1.1578, 1.1573, 1.1533, 1.1453, 1.152, 1.1373, 1.1161, 1.1435, 1.0799, 0.991, 1.1123, 0.8912, 1.1227, 1.0399, 0.8641, 1.0514, 1.0858, 1.0796, 1.087, 0.799, 0.6084, 0.802, 0.7361, 0.9126, 0.7068, 0.7165, 0.8684, 0.4209, 0.7929, 0.8968, 0.646, 0.7085, 0.3592, 0.4504, 0.3811, 0.5373, 0.1903, 0.3207, 0.5628, 0.2069, 0.4797, 0.7468, 0.504, 0.3152, 0.7574, 0.5452, 0.2805, 0.391, 0.4457, 0.4385, 0.1941, 0.1468, -0.1849, 0.1301, 0.2522, 0.0933, -0.1135, -0.1435, 0.0725, 0.0204, -0.0886, -0.1628, -0.8279, -0.5556, -0.3418, -0.0543, -0.5436]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 3, 3, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 3, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 1, 2, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 2, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 3, 1, 2, 3, 1, 3, 1, 2, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3], \"Freq\": [0.17696440676790814, 0.7427996436945954, 0.08002848968485018, 0.5937604957920107, 0.10256771323832828, 0.3037069950433616, 0.9543872566009912, 0.10474173584469572, 0.7497975480589804, 0.14433922134695876, 0.43836757466627146, 0.16072594822205047, 0.40091429668572115, 0.03916283618709673, 0.0587442542806451, 0.9007452323032249, 0.504325330448157, 0.06739487975713594, 0.4282664092470056, 0.6457908113632299, 0.15838312176876454, 0.19585459033147137, 0.30649542147436853, 0.09933977709290928, 0.5940044009105019, 0.246845651034564, 0.13624121985883947, 0.6174803674247401, 0.02910299800803475, 0.9603989342651468, 0.05033735292895695, 0.906072352721225, 0.9427102605092674, 0.9733982298285597, 0.7328773389357115, 0.17055783599215238, 0.09607843162876706, 0.9567169946055984, 0.3588235492113381, 0.5202459605620072, 0.12094634402691924, 0.9255204441014796, 0.03085068147004932, 0.03085068147004932, 0.22345945652614888, 0.2390144078185641, 0.5375322230627092, 0.9529908991989311, 0.04412810664573513, 0.9708183462061729, 0.857282722973494, 0.0680383113471027, 0.07484214248181296, 0.9031373768575347, 0.022864237388798347, 0.0800248308607942, 0.4342630518146124, 0.304577908000491, 0.26116959590176503, 0.9616948118891236, 0.028285141526150696, 0.028285141526150696, 0.707474160400869, 0.12266689071466678, 0.16986186335600942, 0.9352806205807648, 0.03897002585753187, 0.03897002585753187, 0.9432832840910501, 0.04491825162338334, 0.38979419644494345, 0.2563375421181403, 0.35386445173883213, 0.4030842021051146, 0.34830174048606605, 0.2485695667693367, 0.7020674523142216, 0.2492772830686051, 0.048537996703205445, 0.9429326148965134, 0.06286217432643422, 0.30431219058438863, 0.46242236967788347, 0.2332761850012425, 0.9775972074924921, 0.12371703716966824, 0.7526119761154818, 0.12371703716966824, 0.056853071313043874, 0.909649141008702, 0.9120015070291883, 0.462411620799817, 0.2604926617426333, 0.2770716002864454, 0.25311626442860546, 0.23319425345460418, 0.5135254078744792, 0.21909660437878362, 0.18204133974559336, 0.5987660221680583, 0.13517154131384998, 0.02457664387524545, 0.8356058917583453, 0.2565169342009171, 0.09130263759693659, 0.652596471585723, 0.21709459770543466, 0.13253565219033442, 0.6503842298661433, 0.9686467242359996, 0.047829235885121106, 0.047829235885121106, 0.9565847177024221, 0.9691160018558573, 0.9474582063925537, 0.02631828351090427, 0.9361760480897846, 0.04070330643868628, 0.02035165321934314, 0.9291787551563095, 0.0383166496971674, 0.02873748727287555, 0.6601769817107237, 0.15967281572037373, 0.18002770724280098, 0.6624152795678804, 0.1612458246316551, 0.17635354153408045, 0.05117622514932241, 0.9211720526878033, 0.05117622514932241, 0.5415077645876639, 0.27281151142711224, 0.1856884827594399, 0.3423751777041011, 0.2978479965556739, 0.35978310236531885, 0.4465452205939072, 0.34559708438444553, 0.2078557363121924, 0.6908908082987425, 0.12865001958428723, 0.18051205872920303, 0.9653646574630799, 0.9365244495086187, 0.1757334930429798, 0.1110082408122153, 0.713219080745575, 0.09676954294935643, 0.03628857860600866, 0.8709258865442079, 0.20360933198977574, 0.3428220883418456, 0.4535090406315894, 0.08942626620673717, 0.8283696238097759, 0.08236629782199476, 0.3392071397555001, 0.4859375676405628, 0.1748939564610927, 0.09904251887225941, 0.858368496892915, 0.042446793802396895, 0.48911384731712715, 0.1721039281772921, 0.33881958577430366, 0.6250756485893024, 0.10713380413552778, 0.2677455780166262, 0.21965691811342097, 0.6564394966411325, 0.1237503764019273, 0.07742596478204025, 0.6901274971123588, 0.23227789434612073, 0.05302001679383504, 0.8253926938715942, 0.12180274128313456, 0.0750294740540001, 0.7865993247596784, 0.13916757284209696, 0.940366956793816, 0.055315703340812705, 0.06752974260176224, 0.8373688082618518, 0.09454163964246713, 0.28971291521045883, 0.61717539331287, 0.09317550840791386, 0.5683118213500815, 0.1959542714741094, 0.23579682553800618, 0.9731276955119256, 0.9811127502598473, 0.7395898785441731, 0.11474375952083742, 0.14557626633085835, 0.16712512789687767, 0.7354886826866724, 0.0973745579895031, 0.981569266837239, 0.9276836845222703, 0.03865348685509459, 0.03865348685509459, 0.6737511099246057, 0.19667884196900917, 0.12960631381034707, 0.05251498580133851, 0.9452697444240932, 0.9448565943780239, 0.05305885034727498, 0.9550593062509496, 0.05305885034727498, 0.9491125602116106, 0.7147188320001872, 0.12861486228022692, 0.15623684612564478, 0.7946943994456259, 0.10133686972796571, 0.10400362945764903, 0.041764402626126636, 0.9605812604009126, 0.9204342220966905, 0.057527138881043154, 0.9458066201487781, 0.03637717769802993, 0.9649242984977843, 0.9260925072261912, 0.13598001060719841, 0.13598001060719841, 0.7284643425385628, 0.3024199591744044, 0.2132222355500781, 0.4841952213215075, 0.4213570335648775, 0.07803831450047732, 0.5006419665078545, 0.13461149107109563, 0.6914954865732493, 0.1738442943389845, 0.9529784121408983, 0.05956115075880614, 0.9781437355042835, 0.08718756790079259, 0.8967864126938666, 0.02491073368594074, 0.44233559367381814, 0.11204368586593143, 0.4456351132468823, 0.9139944209688824, 0.4482338235697462, 0.23066098487623676, 0.3211521461181039, 0.30837600007481597, 0.0809545493367878, 0.6106687103150756, 0.9853654782324806, 0.024634136955812014, 0.9264170599938036, 0.9178566408380497, 0.6560123739010801, 0.20433870179916838, 0.14005715185818, 0.9439798626304882, 0.018758978932535218, 0.037517957865070437, 0.9567079255592962, 0.9163141706629219, 0.024765247855754645, 0.04953049571150929, 0.9892552031962236, 0.9661855754471081, 0.12473754980519126, 0.6454820421145957, 0.22953563997609544, 0.10209990402678401, 0.030629971208035203, 0.8576391938249857, 0.9491403763639451, 0.03515334727273871, 0.021092008363643226, 0.9614441957729415, 0.02090096077767264, 0.02090096077767264, 0.684332816369292, 0.12585709840384923, 0.18963439489751466, 0.1380395445936219, 0.07362109044993168, 0.787975733721925, 0.5729900195615402, 0.18507323770317005, 0.241987352837552, 0.0091583203256206, 0.0641082422793442, 0.9341486732133011, 0.05627101106539782, 0.928471682579064, 0.02813550553269891, 0.09630103282986671, 0.8103379591781467, 0.09160342147231224, 0.3969593462380346, 0.17056249366297055, 0.4325250680108064, 0.292420801088652, 0.37433267349391475, 0.3332130445007053, 0.9381361833710609, 0.055184481374768286, 0.009197413562461381, 0.12720940055214305, 0.5523049070304434, 0.32072485930714056, 0.08505147032489313, 0.8251262046444856, 0.09012917004578228, 0.029321133158352945, 0.05864226631670589, 0.9382762610672942, 0.9104343941267783, 0.04794557413506811, 0.9589114827013621, 0.04794557413506811, 0.5682549720581462, 0.19334118871800834, 0.2384286596048166, 0.9521254701737027, 0.9470698202892581, 0.447256754112803, 0.41756503207647694, 0.13515779352282362, 0.9338007802785988, 0.24217581573716146, 0.06345650852478335, 0.6940555619898179, 0.0249135674379565, 0.9716291300803035, 0.051277132880811316, 0.9229883918546037, 0.04794561020788816, 0.02397280510394408, 0.9349393990538191, 0.9426874176761396, 0.058917963604758726, 0.06169614226451452, 0.8822548343825576, 0.055526528038063065, 0.1049021390301971, 0.06455516248012129, 0.8271130192765541, 0.05461476428061995, 0.9284509927705391, 0.05461476428061995, 0.1380323491153051, 0.7813249015220814, 0.08034718829099849, 0.18814860240011383, 0.5574150714485907, 0.25448206579706706, 0.12239012526999384, 0.7098627265659643, 0.16784931465599154, 0.7132045766136842, 0.1589691864970168, 0.12782763838112204, 0.13614007180617604, 0.7434235038962635, 0.12051069800365433, 0.056578760784794915, 0.8062473411833275, 0.13673200522992104, 0.060866925947009064, 0.8643103484475286, 0.07304031113641088, 0.13729633817001657, 0.7350103336497994, 0.1277978493658016, 0.9535299953094887, 0.03288034466584444, 0.03288034466584444, 0.024306870307895297, 0.9236610717000212, 0.048613740615790595, 0.07203985689837296, 0.06843786405345431, 0.8608762899355569, 0.061570489754368164, 0.05130874146197347, 0.8927721014383384, 0.10584878900423747, 0.8398871301423191, 0.05522545513264564, 0.6428333904978286, 0.18931436666511745, 0.16785985238462223, 0.6010035187807345, 0.18311907805973923, 0.21590870702581383, 0.20473800881737506, 0.550984327226368, 0.24430208165345346, 0.09525600207294621, 0.562304153205938, 0.3424180515045115, 0.19432699834542247, 0.15930693857292585, 0.6461544361944966, 0.09272480576590486, 0.8310889998277399, 0.07898779750428932, 0.10733904576627905, 0.8432121429148852, 0.04960071428911089, 0.9186389649825619, 0.0459319482491281, 0.0459319482491281, 0.9805209470277242, 0.9296230478453469, 0.04460767504912705, 0.04460767504912705, 0.936761176031668, 0.45430844767354067, 0.16924839778995243, 0.37645995124545356, 0.1184433953123418, 0.7825724333136869, 0.0987028294269515, 0.9253182457323076, 0.03637089058369764, 0.03744062265968875, 0.9760648782638165, 0.9100637519695631, 0.07222728190234629, 0.02889091276093851, 0.17462055968867077, 0.6687736369172911, 0.15646530301026454, 0.7467100701776963, 0.16371088289384825, 0.09068876246637636, 0.05000159000791999, 0.9500302101504798, 0.045703777758339344, 0.9597793329251262, 0.6194464181999108, 0.18070456953822112, 0.19982372652055166, 0.14973082672474933, 0.780274308211582, 0.06975038512022484, 0.1747831724038106, 0.6880646259274021, 0.13742845745734977, 0.18037173405893953, 0.10202845562929912, 0.717843062820426, 0.9213333559943877, 0.06580952542817055, 0.9258052594858459, 0.12276108331883694, 0.7458607144229651, 0.13166803889086612, 0.3814871838478565, 0.4668500118563459, 0.1516777522464894, 0.03993544636923384, 0.863295883858376, 0.0966339196095041, 0.4678958241003901, 0.07525720132091956, 0.4568182454012828, 0.2451306275704434, 0.5025177865194089, 0.25230945309214925, 0.043630930892785094, 0.7914046078770524, 0.16501995644597928, 0.052964820642549426, 0.9401255664052524, 0.9072041016239656, 0.04612902211647283, 0.06150536282196377, 0.31510756678783, 0.2817310215315941, 0.4031752305746409, 0.41067542863773937, 0.29079698564078715, 0.2985534186943161, 0.3708958963567368, 0.3756452813388061, 0.2534484882954724, 0.792733937905443, 0.10593067305344392, 0.10243845306267105, 0.3022898573930416, 0.1931694270386814, 0.5045327556646895, 0.559852279082605, 0.20996482468917116, 0.23018485788342877, 0.04957368863342089, 0.04957368863342089, 0.9419000840349968, 0.923875186581479, 0.034645319496805466, 0.034645319496805466, 0.9463124191370554, 0.5206728501366477, 0.18343179184245137, 0.29601810337985657, 0.5524333259999026, 0.1330153995357683, 0.3145634448481007, 0.9197118134117438, 0.06131412089411625, 0.12394110639222956, 0.6402022523981057, 0.23603254628184286, 0.31090220561082726, 0.2701277803948368, 0.4189577764265221, 0.05399999066154253, 0.9179998412462229, 0.34261344285274353, 0.30222571721179886, 0.3552346071155387, 0.06881594611225272, 0.02293864870408424, 0.9098997319286749, 0.02417486056407058, 0.9669944225628233, 0.7463228609802586, 0.07600459121722576, 0.17734404617352678, 0.9611465789111165, 0.03203821929703722, 0.01601910964851861, 0.3202868663587425, 0.22070535560565246, 0.45896564212409613, 0.6525932860623689, 0.2162938450703094, 0.13092357548717637, 0.7737764282698911, 0.1545620830501655, 0.07148496341070155, 0.8116924700141913, 0.10854027215306046, 0.08022541854791425, 0.1693965391888465, 0.2069514323109021, 0.624050458049477, 0.056786705238742186, 0.014196676309685546, 0.9227839601295605, 0.9391388619797355, 0.049428361156828186, 0.3430313430693803, 0.46044770170157384, 0.19653523206566223, 0.055714275558809305, 0.9471426844997581, 0.36789133789321093, 0.38893696843096776, 0.24316061515416354, 0.5322201750682909, 0.29734909780989294, 0.1704261560599114, 0.9364895338930276, 0.3363932883527202, 0.2763368200835633, 0.38725687834419675, 0.34712688103841155, 0.4358144955936133, 0.2170178304588605, 0.030647109510119015, 0.9500603948136895, 0.9433815454308059, 0.04965166028583189, 0.015265317396724508, 0.015265317396724508, 0.9617149959936441, 0.4435763563913674, 0.08379035920781419, 0.4726578507440795, 0.05815722178630882, 0.9305155485809411, 0.9878333117335975, 0.022972867714734824, 0.11105629958345992, 0.19057809434692505, 0.6965012368937981, 0.9491679427384805, 0.021571998698601828, 0.021571998698601828, 0.9553035010658133, 0.08183417412816524, 0.810396675832316, 0.10725838356604182, 0.9673841565732215, 0.9202470360895215, 0.03680988144358086, 0.03680988144358086, 0.3135590139265428, 0.09323891383278254, 0.5930455358845625, 0.9383955589874059, 0.0665675207999405, 0.8986615307991966, 0.03328376039997025, 0.11200547882695494, 0.02240109576539099, 0.862442186967553, 0.7414304966489478, 0.13535984396058093, 0.12316526342359166, 0.7075609853704999, 0.19764683807337952, 0.09478231268202958, 0.2079066719542351, 0.5888720225521943, 0.20318152031891157, 0.3996872566187037, 0.3970327032207491, 0.2032503051700603, 0.2426377875120352, 0.19914075623552072, 0.5580858230304099, 0.06550915370278186, 0.052407322962225486, 0.8909244903578332, 0.9305134140009347, 0.037520702177457045, 0.037520702177457045, 0.9213920002757637, 0.018427840005515273, 0.07371136002206109, 0.9408015238928007, 0.9283393596637295, 0.06514662173078803, 0.6285230820288937, 0.16208510943791918, 0.2094381594281478], \"Term\": [\"aceptable\", \"aceptable\", \"aceptable\", \"acogedor\", \"acogedor\", \"acogedor\", \"acristalado\", \"actitud\", \"actitud\", \"actitud\", \"agradable\", \"agradable\", \"agradable\", \"ambientar\", \"ambientar\", \"ambientar\", \"ambiente\", \"ambiente\", \"ambiente\", \"amigo\", \"amigo\", \"amigo\", \"amplio\", \"amplio\", \"amplio\", \"aniversario\", \"aniversario\", \"aniversario\", \"anti\", \"anti\", \"antioquen\", \"antioquen\", \"arigato\", \"arquitecturo\", \"artesanal\", \"artesanal\", \"artesanal\", \"asemejo\", \"asi\", \"asi\", \"asi\", \"astrid\", \"astrid\", \"astrid\", \"atencion\", \"atencion\", \"atencion\", \"baguettir\", \"barroco\", \"barroco\", \"best\", \"best\", \"best\", \"bicono\", \"bicono\", \"bicono\", \"bien\", \"bien\", \"bien\", \"big\", \"big\", \"big\", \"bogota\", \"bogota\", \"bogota\", \"bon\", \"bon\", \"bon\", \"bucco\", \"bucco\", \"buen\", \"buen\", \"buen\", \"bueno\", \"bueno\", \"bueno\", \"cafe\", \"cafe\", \"cafe\", \"cafecito\", \"cafecito\", \"calidad\", \"calidad\", \"calidad\", \"camila\", \"cara\", \"cara\", \"cara\", \"carente\", \"carente\", \"carinoso\", \"carne\", \"carne\", \"carne\", \"carta\", \"carta\", \"carta\", \"cartar\", \"cartar\", \"cartar\", \"cavo\", \"cavo\", \"cavo\", \"celebracion\", \"celebracion\", \"celebracion\", \"celebrar\", \"celebrar\", \"celebrar\", \"centimetro\", \"ceramico\", \"ceramico\", \"ceramico\", \"chatear\", \"chateaubriand\", \"chateaubriand\", \"chocolo\", \"chocolo\", \"chocolo\", \"chorro\", \"chorro\", \"chorro\", \"ciudad\", \"ciudad\", \"ciudad\", \"colombia\", \"colombia\", \"colombia\", \"comence\", \"comence\", \"comence\", \"comer\", \"comer\", \"comer\", \"comida\", \"comida\", \"comida\", \"comido\", \"comido\", \"comido\", \"compartir\", \"compartir\", \"compartir\", \"coqueto\", \"cotta\", \"cumpleano\", \"cumpleano\", \"cumpleano\", \"danielar\", \"danielar\", \"danielar\", \"dar\", \"dar\", \"dar\", \"decepcionante\", \"decepcionante\", \"decepcionante\", \"decir\", \"decir\", \"decir\", \"deficiente\", \"deficiente\", \"deficiente\", \"delicios\", \"delicios\", \"delicios\", \"delicioso\", \"delicioso\", \"delicioso\", \"demasiado\", \"demasiado\", \"demasiado\", \"demorado\", \"demorado\", \"demorado\", \"demorar\", \"demorar\", \"demorar\", \"demoro\", \"demoro\", \"demoro\", \"desfile\", \"desfile\", \"desmejorado\", \"desmejorado\", \"desmejorado\", \"despu\", \"despu\", \"despu\", \"diferente\", \"diferente\", \"diferente\", \"discapacidad\", \"disculpar el\", \"disfrutar\", \"disfrutar\", \"disfrutar\", \"domicilio\", \"domicilio\", \"domicilio\", \"domino\", \"dry\", \"dry\", \"dry\", \"dudar\", \"dudar\", \"dudar\", \"dw\", \"dw\", \"edificacion\", \"empeorar\", \"empeorar\", \"empeorar\", \"enano\", \"encantador\", \"encantador\", \"encantador\", \"encarecidamente\", \"encarecidamente\", \"encarecidamente\", \"enhorabuena\", \"enhorabuena\", \"entradita\", \"entradita\", \"escargot\", \"escargot\", \"esfero\", \"esforzar el\", \"esmerado\", \"esmerado\", \"esmerado\", \"especial\", \"especial\", \"especial\", \"espectacular\", \"espectacular\", \"espectacular\", \"esperar\", \"esperar\", \"esperar\", \"estomacal\", \"estomacal\", \"estricto\", \"eternidad\", \"eternidad\", \"eternidad\", \"excelente\", \"excelente\", \"excelente\", \"experencia\", \"experiencia\", \"experiencia\", \"experiencia\", \"exquisito\", \"exquisito\", \"exquisito\", \"extravagante\", \"extravagante\", \"fabricar\", \"falencia\", \"fantastico\", \"fantastico\", \"fantastico\", \"felicitacionesma\", \"fernandez\", \"fernandez\", \"fernandez\", \"fi\", \"fi\", \"fi\", \"fire\", \"friends\", \"frio\", \"frio\", \"frio\", \"gabriel\", \"gabriel\", \"gabriel\", \"gaira\", \"gaira\", \"gaira\", \"gaston\", \"gaston\", \"gaston\", \"genial\", \"genial\", \"genial\", \"gracia\", \"gracia\", \"gracia\", \"gran\", \"gran\", \"gran\", \"gris\", \"gris\", \"gris\", \"groserio\", \"groserio\", \"groserio\", \"grosero\", \"grosero\", \"grosero\", \"gusto\", \"gusto\", \"gusto\", \"hacer\", \"hacer\", \"hacer\", \"hard\", \"hard\", \"hard\", \"hora\", \"hora\", \"hora\", \"horrible\", \"horrible\", \"horrible\", \"huesito\", \"huesito\", \"huesito\", \"identificacion\", \"ignoro\", \"ignoro\", \"ignoro\", \"increible\", \"increible\", \"increible\", \"informalidad\", \"intrigante\", \"ir\", \"ir\", \"ir\", \"italianisimo\", \"italiano\", \"italiano\", \"italiano\", \"jessico\", \"jessico\", \"johan\", \"johan\", \"katherine\", \"katherine\", \"katherine\", \"kibbe\", \"kibbe\", \"lamentable\", \"lamentable\", \"lamentable\", \"laura\", \"laura\", \"laura\", \"lentisimo\", \"lentisimo\", \"lentisimo\", \"lento\", \"lento\", \"lento\", \"llegar\", \"llegar\", \"llegar\", \"llego\", \"llego\", \"llego\", \"lugar\", \"lugar\", \"lugar\", \"mal\", \"mal\", \"mal\", \"mala\", \"mala\", \"mala\", \"malisimo\", \"malisimo\", \"malisimo\", \"malo\", \"malo\", \"malo\", \"mandarino\", \"mandarino\", \"mandarino\", \"mantenimiento\", \"mantenimiento\", \"mantenimiento\", \"mariachis\", \"mariachis\", \"mariachis\", \"marrano\", \"marrano\", \"marrano\", \"mediocre\", \"mediocre\", \"mediocre\", \"mejor\", \"mejor\", \"mejor\", \"menu\", \"menu\", \"menu\", \"mesa\", \"mesa\", \"mesa\", \"mesero\", \"mesero\", \"mesero\", \"mil\", \"mil\", \"mil\", \"min\", \"min\", \"min\", \"minuto\", \"minuto\", \"minuto\", \"monteria\", \"monteria\", \"monteria\", \"motor\", \"mozos\", \"muchacha\", \"muchacha\", \"muchacha\", \"musico\", \"musico\", \"musico\", \"nadie\", \"nadie\", \"nadie\", \"nar\", \"nar\", \"nar\", \"nombrado\", \"nueva\", \"nueva\", \"nueva\", \"nunca\", \"nunca\", \"nunca\", \"obligado\", \"obligado\", \"obligado\", \"obligatoriamente\", \"obligatoriamente\", \"once\", \"once\", \"opcion\", \"opcion\", \"opcion\", \"orden\", \"orden\", \"orden\", \"pagar\", \"pagar\", \"pagar\", \"paisa\", \"paisa\", \"paisa\", \"parejama\", \"parejama\", \"pastelero\", \"pedido\", \"pedido\", \"pedido\", \"pedir\", \"pedir\", \"pedir\", \"peor\", \"peor\", \"peor\", \"perfecto\", \"perfecto\", \"perfecto\", \"persona\", \"persona\", \"persona\", \"pesimo\", \"pesimo\", \"pesimo\", \"pianista\", \"pianista\", \"place\", \"place\", \"place\", \"plato\", \"plato\", \"plato\", \"poder\", \"poder\", \"poder\", \"precio\", \"precio\", \"precio\", \"precioso\", \"precioso\", \"precioso\", \"presentacion\", \"presentacion\", \"presentacion\", \"probar\", \"probar\", \"probar\", \"puchero\", \"puchero\", \"puchero\", \"quevedo\", \"quevedo\", \"quevedo\", \"racista\", \"recomeir\", \"recomeir\", \"recomeir\", \"recomendado\", \"recomendado\", \"recomendado\", \"reforma\", \"reforma\", \"regular\", \"regular\", \"regular\", \"restaurante\", \"restaurante\", \"restaurante\", \"restrepo\", \"restrepo\", \"rico\", \"rico\", \"rico\", \"rocio\", \"rocio\", \"rocio\", \"ronald\", \"ronald\", \"rumba\", \"rumba\", \"rumba\", \"rumbo\", \"rumbo\", \"rumbo\", \"sabor\", \"sabor\", \"sabor\", \"sabroso\", \"sabroso\", \"sabroso\", \"saludable\", \"saludable\", \"saludable\", \"sano\", \"sano\", \"sano\", \"sazon\", \"sazon\", \"sazon\", \"sebastian\", \"sebastian\", \"sebastian\", \"seguiar\", \"seguiar\", \"ser\", \"ser\", \"ser\", \"servcio\", \"servcio\", \"servicio\", \"servicio\", \"servicio\", \"siempre\", \"siempre\", \"siempre\", \"simbolo\", \"sitio\", \"sitio\", \"sitio\", \"solo\", \"solo\", \"solo\", \"souvenirs\", \"souvenirs\", \"stephany\", \"stephany\", \"sumo\", \"sumo\", \"sumo\", \"super\", \"super\", \"super\", \"talla\", \"talla\", \"tatiana\", \"tatiana\", \"tematico\", \"tematico\", \"tematico\", \"teo\", \"teo\", \"teo\", \"terracitar\", \"terrible\", \"terrible\", \"terrible\", \"tertuliar\", \"this\", \"this\", \"this\", \"tipico\", \"tipico\", \"tipico\", \"todoma\", \"traerno\", \"traerno\", \"traerno\", \"trattoria\", \"trattoria\", \"trattoria\", \"vegetarian\", \"vegetarian\", \"vegetarian\", \"vegetariano\", \"vegetariano\", \"vegetariano\", \"ver\", \"ver\", \"ver\", \"vez\", \"vez\", \"vez\", \"vino\", \"vino\", \"vino\", \"vistas\", \"vistas\", \"vistas\", \"vives\", \"vives\", \"vives\", \"was\", \"was\", \"was\", \"yasai\", \"z\", \"z\", \"zona\", \"zona\", \"zona\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el201621406717999771204876707238\", ldavis_el201621406717999771204876707238_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el201621406717999771204876707238\", ldavis_el201621406717999771204876707238_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el201621406717999771204876707238\", ldavis_el201621406717999771204876707238_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.027942  0.028041       1        1  39.022465\n",
       "2      0.051333  0.001708       2        1  31.723365\n",
       "0     -0.023391 -0.029749       3        1  29.254170, topic_info=            Term          Freq         Total Category  logprob  loglift\n",
       "175    excelente  50007.000000  50007.000000  Default  30.0000  30.0000\n",
       "177        lugar  47524.000000  47524.000000  Default  29.0000  29.0000\n",
       "80      atencion  34972.000000  34972.000000  Default  28.0000  28.0000\n",
       "59      ambiente  28162.000000  28162.000000  Default  27.0000  27.0000\n",
       "55   restaurante  44856.000000  44856.000000  Default  26.0000  26.0000\n",
       "..           ...           ...           ...      ...      ...      ...\n",
       "177        lugar   6075.096966  47524.933394   Topic3  -4.9786  -0.8279\n",
       "135        mejor   5022.551129  29923.772294   Topic3  -5.1689  -0.5556\n",
       "44        comido   4010.827815  19297.037797   Topic3  -5.3938  -0.3418\n",
       "23         carne   3543.187390  12787.308394   Topic3  -5.5178  -0.0543\n",
       "207       bogota   3394.081411  19980.941766   Topic3  -5.5608  -0.5436\n",
       "\n",
       "[324 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "807       1  0.176964  aceptable\n",
       "807       2  0.742800  aceptable\n",
       "807       3  0.080028  aceptable\n",
       "199       1  0.593760   acogedor\n",
       "199       2  0.102568   acogedor\n",
       "...     ...       ...        ...\n",
       "7970      1  0.928339          z\n",
       "7970      3  0.065147          z\n",
       "100       1  0.628523       zona\n",
       "100       2  0.162085       zona\n",
       "100       3  0.209438       zona\n",
       "\n",
       "[644 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que puede seleccionar manualmente cada tema para ver sus términos más frecuentes y/o \"relevantes\", utilizando diferentes valores del parámetro $\\lambda$. Esto puede ayudar cuando intenta asignar un nombre interpretable por humanos o un \"significado\" a cada tema.\n",
    "\n",
    "Los valores de lambda ($\\lambda$) que están muy cerca de cero mostrarán términos que son más específicos para un tema elegido. Lo que significa que verá términos que son \"importantes\" para ese tema específico pero no necesariamente \"importantes\" para todo el corpus.\n",
    "\n",
    "Los valores de lambda que están muy cerca de uno mostrarán aquellos términos que tienen la relación más alta entre la frecuencia de los términos para ese tema específico y la frecuencia general de los términos del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos la visualización como un html. \n",
    "# Es mucho más sencillo interactuar con la gráfica desde el archivo que \n",
    "# desde el notebook\n",
    "pyLDAvis.save_html(LDA_visualization, 'visualizacion_LDA.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones Finales\n",
    "\n",
    "Cuando debemos extraer información de una gran colección de documentos aún no vista, el modelado de tópicos es un gran enfoque, ya que proporciona información sobre la estructura subyacente de los documentos. Es decir, los modelos de tópicos encuentran agrupaciones de palabras utilizando la proximidad, no el contexto.\n",
    "\n",
    "En este cuaderno, aprendimos cómo aplicar dos de los algoritmos de modelado de tópicos más comunes y efectivos: la asignación de Dirichlet latente y la factorización de matriz no negativa. Ahora deberíamos sentirnos cómodos limpiando documentos de texto sin formato utilizando varias técnicas diferentes; técnicas que se pueden utilizar en muchos otros escenarios de modelado. Continuaremos aprendiendo cómo convertir el corpus limpio en la estructura de datos adecuada de recuentos de palabras sin procesar o pesos de palabras por documento mediante la aplicación de modelos de bolsa de palabras.\n",
    "\n",
    "El enfoque principal del cuaderno fue ajustar los dos modelos de tópicos, incluida la optimización de la cantidad de tópicos, la conversión de la salida en tablas fáciles de interpretar y la visualización de los resultados. Con esta información, deberíamos poder aplicar modelos de tópicos completamente funcionales para obtener valor e información para cualquier negocio.\n",
    "\n",
    "\n",
    "\n",
    "Los modelos de tópicos se pueden usar para predecir los tópicos que pertenecen a documentos no vistos, pero si vamos a hacer predicciones, es importante reconocer que los modelos de tópicos sólo conocen las palabras que se usan para entrenarlos. Es decir, si los documentos no vistos tienen palabras que no estaban en los datos de entrenamiento, el modelo no podrá procesar esas palabras incluso si se vinculan a uno de los tópico identificados en los datos de entrenamiento. Debido a este hecho, los modelos de tópicos tienden a usarse más para el análisis exploratorio y la inferencia que para la predicción.\n",
    "\n",
    "Cada modelo de tópicos genera dos matrices. La primera matriz contiene palabras contra tópicos. Esta enumera cada palabra relacionada con cada tópico con alguna cuantificación de la relación. Dada la cantidad de palabras que considera el modelo, cada tópico sólo se describirá con una cantidad relativamente pequeña de palabras.\n",
    "\n",
    "Las palabras se pueden asignar a un tópico o a varios tópicos con diferentes cuantificaciones. Si las palabras se asignan a uno o varios tópicos depende del algoritmo. De manera similar, la segunda matriz contiene documentos contra tópicos. Esta asigna cada documento a cada tópico mediante alguna cuantificación de la relación de cada combinación de tópico del documento.\n",
    "\n",
    "Cuando se analiza el modelado de tópicos, es importante reforzar continuamente el hecho de que los grupos de palabras que representan los tópicos no están relacionados conceptualmente; están relacionados solo por proximidad. La proximidad frecuente de ciertas palabras en los documentos es suficiente para definir tópicos debido a una suposición establecida anteriormente: que todas las palabras en el mismo documento están relacionadas.\n",
    "\n",
    "Sin embargo, esta suposición puede no ser cierta o las palabras pueden ser demasiado genéricas para formar tópicos coherentes. La interpretación de tópicos abstractos implica equilibrar las características innatas de los datos de texto con las agrupaciones de palabras generadas. Los datos de texto, y el lenguaje en general, son muy variables, complejos y contextuales, lo que significa que cualquier resultado generalizado debe consumirse con cautela.\n",
    "\n",
    "Esto no es para minimizar o invalidar los resultados del modelo. Dados documentos cuidadosamente limpios y una cantidad adecuada de tópicos, las agrupaciones de palabras, como veremos, pueden ser una buena guía sobre lo que contiene un corpus y pueden incorporarse de manera efectiva en sistemas de datos más grandes.\n",
    "\n",
    "Ya discutimos algunas de las limitaciones de los modelos de tópicos, pero hay algunos puntos adicionales que debemos considerar. La naturaleza ruidosa de los datos de texto puede hacer que los modelos de tópico asignen palabras no relacionadas con uno de los tópicos a ese tópico en particular.\n",
    "\n",
    "Nuevamente, consideremos la oración sobre el trabajo de antes. La palabra reunión podría aparecer en la agrupación de palabras que representa el tópico de trabajo. También es posible que la palabra larga pueda estar en ese grupo, pero la palabra larga no está directamente relacionada con el trabajo. Larga puede estar en el grupo porque aparece con frecuencia muy cerca de la palabra reunión. Por lo tanto, larga probablemente se consideraría falsamente (o espuriamente) correlacionado con el trabajo y probablemente debería eliminarse de la agrupación de tópicos, si es posible. Las palabras falsamente correlacionadas en grupos de palabras pueden causar problemas significativos cuando analizando los datos.\n",
    "\n",
    "Esto no es necesariamente una falla en el modelo. En cambio, es una característica que, dados datos ruidosos, el modelo podría extraer peculiaridades de los datos que podrían afectar negativamente los resultados. Las correlaciones espurias podrían ser el resultado de cómo, dónde o cuándo se recopilaron los datos. Si los documentos se recopilaron sólo en una región geográfica específica, las palabras asociadas con esa región podrían vincularse incorrectamente, aunque accidentalmente, a una o varias de las agrupaciones de palabras resultantes del modelo.\n",
    "\n",
    "Tenga en cuenta que, con palabras adicionales en el grupo de palabras, podríamos adjuntar más documentos a ese tópico de los que deberían adjuntarse. Si reducimos la cantidad de palabras que pertenecen a un tópico, ese tópico se asignará a menos documentos. Tenga en cuenta que esto no es algo malo. Queremos que cada grupo de palabras contenga solo palabras que tengan sentido para que podamos asignar los tópicos apropiados a los documentos apropiados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- Banik, R. (2018). Hands-on recommendation systems with Python: start building powerful and personalized, recommendation engines with Python. Packt Publishing Ltd.\n",
    "\n",
    "- Blei, D. M., Jordan, M. I., &; Ng, A. Y. (2003). Latent Dirichlet Allocation. JMLR.org, 3, 993–1022. https://doi.org/10.5555/944919.944937 \n",
    "\n",
    "- Patel, A. A. (2019). Hands-on unsupervised learning using Python: how to build applied machine learning solutions from unlabeled data. O'Reilly Media.\n",
    "\n",
    "- Murphy, K. P. (2012). Machine learning: a probabilistic perspective. MIT press."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe36d3cf18f454bb22b210d1ce52ae8c21a1b2f0a9257a143474ae90bef14b60"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
